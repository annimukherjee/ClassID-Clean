{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f1bf94-25d4-4ed1-bddd-bc3309763692",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "from matplotlib import pyplot as plt, rcParams\n",
    "# import cv2\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style=\"white\", context=\"paper\")\n",
    "from cycler import cycler\n",
    "import os, sys\n",
    "import glob\n",
    "from datetime import datetime, timedelta\n",
    "from itertools import combinations\n",
    "import base64\n",
    "from PIL import Image\n",
    "from io import BytesIO as _BytesIO\n",
    "import requests\n",
    "import json\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from IPython.display import display, Markdown, Latex\n",
    "from sklearn.metrics import *\n",
    "import collections\n",
    "from copy import deepcopy\n",
    "import traceback\n",
    "from sympy import Point, Polygon\n",
    "import mmcv\n",
    "import cv2\n",
    "from mmtrack.apis import inference_mot, init_model as init_tracking_model\n",
    "from smartprint import smartprint as sprint\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "def printm(s): return display(Markdown(s))\n",
    "    \n",
    "SERVER_CACHE_DIR = '/mnt/ci-nas-cache/edulyzeV2/cache_compute_4/fixed_face'\n",
    "os.makedirs(SERVER_CACHE_DIR,exist_ok=True)\n",
    "\n",
    "track_analysis_meta_cache = f'{SERVER_CACHE_DIR}/analysis_tracking/meta_info'\n",
    "os.makedirs(track_analysis_meta_cache,exist_ok=True)\n",
    "base_dir = '/mnt/ci-nas-cache/edulyzeV2/pose_face_gaze_emb_fixed_face'\n",
    "\n",
    "track_analysis_session_data = f'{SERVER_CACHE_DIR}/analysis_tracking/session_tracking_info'\n",
    "os.makedirs(track_analysis_session_data,exist_ok=True)\n",
    "\n",
    "postprocessed_id_map_data_dir = f'{SERVER_CACHE_DIR}/analysis_tracking/processed_id_maps'\n",
    "os.makedirs(postprocessed_id_map_data_dir, exist_ok=True)\n",
    "\n",
    "id_viz_cache_root = f'{SERVER_CACHE_DIR}/analysis_tracking/session_matching_info'\n",
    "os.makedirs(id_viz_cache_root, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0bbcd1-d9c5-401f-a2dc-d9ed115f0daf",
   "metadata": {},
   "source": [
    "## Postprocess mmtrack results and create a new tracking map from older tracking ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde910ad-f79e-4ee5-84d7-a8dc1763d2d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "session_id = 'classinsight-cmu_05748A_ghc_4101_201902051630-front'\n",
    "course = '05748A'\n",
    "\n",
    "session_tracking_cache_file = f\"{track_analysis_session_data}/{session_id}.pb\"\n",
    "session_frame_dir = f'/mnt/ci-nas-cache/edulyzeV2/pose_face_gaze_emb_fixed_face/{course}/{session_id}'\n",
    "df_tracking = pickle.load(open(session_tracking_cache_file,\"rb\")).transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663658e4-0d72-402f-8af1-2dc8f4a739ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tracking.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d479503a-6492-4766-a86c-2abcaeb05915",
   "metadata": {},
   "outputs": [],
   "source": [
    "printm(f'## Raw tracking shape:{df_tracking.shape}')\n",
    "printm(f'## Filter non-persistentids')\n",
    "MIN_ID_FRAMES = 900 # number of frames an id needs to be a persistent id\n",
    "col_start_stop_idxs = []\n",
    "for col in df_tracking.columns:\n",
    "    one_idxs = df_tracking.index[np.where(df_tracking[col]==1)[0]].values\n",
    "    col_start_stop_idxs.append([col, one_idxs.min(), one_idxs.max()])\n",
    "df_id_start_stop = pd.DataFrame(col_start_stop_idxs, columns=['id','min_idx','max_idx'])\n",
    "df_id_start_stop['total_idxs'] = df_id_start_stop['max_idx']-df_id_start_stop['min_idx']\n",
    "\n",
    "total_idxs = df_tracking.index.max()\n",
    "\n",
    "# _ = plt.figure(figsize=(20,15))\n",
    "# for row_idx, row in df_id_start_stop.iterrows():\n",
    "#     plt.axhline(y=row_idx, xmin=row['min_idx']/total_idxs,xmax=row['max_idx']/total_idxs)\n",
    "# plt.yticks(range(df_id_start_stop.shape[0]), range(df_id_start_stop.shape[0]))\n",
    "# plt.grid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95faa38f-0a86-4c68-bfd4-d68252e67c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_idxs, np.arange(0,1.1,1/4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00139a07-0a85-40a9-859c-0adc0d34d3dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nonpersistent_ids_removed = df_id_start_stop[df_id_start_stop.total_idxs<=MIN_ID_FRAMES].sort_values(by=['total_idxs'], ascending=False)['id'].values\n",
    "print(nonpersistent_ids_removed[:10])\n",
    "printm(f'### Total ids before filtering: {df_id_start_stop.shape[0]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a398ec9b-eb62-446b-b3e0-77b96845c00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_filtered_ids = [302,941,331,831,566,471]\n",
    "selected_mapped_ids = [10,38, 163,185, 460, 50, 1310, 120, 627, 627, 805]\n",
    "all_selected_ids = selected_filtered_ids + selected_mapped_ids\n",
    "total_idxs = df_tracking.index.max()\n",
    "df_id_start_stop = df_id_start_stop[(df_id_start_stop['id'].isin(all_selected_ids))].reset_index(drop=True)\n",
    "_ = plt.figure(figsize=(10,6))\n",
    "y_tick_labels= []\n",
    "for row_idx, row in df_id_start_stop.iterrows():\n",
    "    plt.axhline(y=row_idx, xmin=row['min_idx']/total_idxs,xmax=row['max_idx']/total_idxs, linewidth=3)\n",
    "    y_tick_labels.append(row['id'])\n",
    "plt.yticks(range(df_id_start_stop.shape[0]), y_tick_labels, fontsize=16)\n",
    "plt.xticks(np.arange(0,1.1,1/4), [f'{xr}:00' for xr in [0,20,40,60,80]], fontsize=24)\n",
    "plt.xlabel(\"Time (in minutes)\", fontsize=24)\n",
    "plt.ylabel(\"Student IDs\", fontsize=24)\n",
    "plt.grid()\n",
    "plt.savefig('plots/local_reconcilition_temporal_v2.png', bbox_inches='tight', dpi=250)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad997bb9-b90b-49eb-b0d3-84c055b5d678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_filtered_ids = deepcopy(nonpersistent_ids_removed)\n",
    "# selected_filtered_ids\n",
    "# array([560, 312, 257, 589, 442, 156, 594, 148, 512, 725, 359, 162, 767,\n",
    "#        313, 732])\n",
    "# selected_mapped_ids = [0,40, 328, 15, 155, 43, 105, 44, 246, 97, 142]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5af294e-01f7-4548-991b-3f625f38f5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "{0: 0, 1: 1, 4: 2, 5: 3, 7: 4, 8: 5, 9: 6, 14: 7, 15: 8, 24: 9, 38: 10, 43: 11, 44: 12, 48: 13, 68: 14, 88: 15, 97: 16, 99: 17, 108: 18, 129: 19, 145: 20, 153: 21, 165: 22, 198: 23, 205: 24, 255: 25, 293: 26, 323: 27, 418: 28, 438: 29, 469: 30, 529: 31, 542: 32, 709: 33, 851: 34, 897: 35, 926: 36}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f836fae-26f6-49b4-80c6-f661d45822e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_id_start_stop = df_id_start_stop[df_id_start_stop.total_idxs>MIN_ID_FRAMES].reset_index(drop=True)\n",
    "printm(f'### Total ids after filtering: {df_id_start_stop.shape[0]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84f947c-436c-4b75-ac24-c50af8559598",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "printm(f'## Map ids into one based on bbox overlap and id start/stop distance')\n",
    "MAX_ID_DISTANCE = 900\n",
    "MAX_BBOX_OVERLAP = 0.4\n",
    "bbox_dict = {}\n",
    "potential_id_maps = {}\n",
    "num_possible_maps = 0 \n",
    "for row_idx, row in df_id_start_stop.iterrows():\n",
    "    row_maxidx = row['max_idx']\n",
    "    \n",
    "    # get polygon for given id\n",
    "    id_max_frame = row_maxidx\n",
    "    id_frame_data = pickle.load(open(f\"{session_frame_dir}/{id_max_frame}.pb\",\"rb\"))[1]\n",
    "    id_frame_data = [xr for xr in id_frame_data if (xr['track_id']==row['id'])][0]\n",
    "    id_bb = id_frame_data['bbox'][:4].astype(int)\n",
    "    X_TL1, Y_TL1, X_BR1, Y_BR1 = id_bb\n",
    "    p1, p2, p3, p4  = map(Point, [[X_TL1,Y_TL1], [X_TL1,Y_BR1], [X_BR1,Y_BR1],[X_BR1, Y_TL1]]) \n",
    "    id_polygon = Polygon(p1, p2, p3, p4)\n",
    "    \n",
    "    potential_id_matches = df_id_start_stop[(df_id_start_stop.min_idx<=row_maxidx+MAX_ID_DISTANCE) & (df_id_start_stop.min_idx>row_maxidx-MAX_ID_DISTANCE)].id.values\n",
    "    successful_matches = []\n",
    "    if len(potential_id_matches)>0:\n",
    "        num_possible_maps+=1\n",
    "        # print('\\n',row['id'], potential_id_matches, row['min_idx'],row['max_idx'],row['total_idxs'])\n",
    "        for matched_id in potential_id_matches:\n",
    "            matched_id_min_frame = df_id_start_stop[df_id_start_stop.id==matched_id].min_idx.values[0]\n",
    "            matched_id_frame_data = pickle.load(open(f\"{session_frame_dir}/{matched_id_min_frame}.pb\",\"rb\"))[1]\n",
    "            matched_id_frame_data = [xr for xr in matched_id_frame_data if (xr['track_id']==matched_id)][0]\n",
    "            matched_id_bb = matched_id_frame_data['bbox'][:4].astype(int)\n",
    "            X_TL2, Y_TL2, X_BR2, Y_BR2 = matched_id_bb\n",
    "            \n",
    "            p1, p2, p3, p4  = map(Point, [[X_TL2,Y_TL2], [X_TL2,Y_BR2], [X_BR2,Y_BR2],[X_BR2, Y_TL2]]) \n",
    "            matched_id_polygon = Polygon(p1, p2, p3, p4)\n",
    "            \n",
    "            #find intersection of two polygons\n",
    "            # check if intersection exists\n",
    "            if id_polygon.encloses_point(matched_id_polygon.centroid) & matched_id_polygon.encloses_point(id_polygon.centroid):\n",
    "                X_TL_in, X_BR_in = sorted([X_TL1,X_TL2, X_BR1, X_BR2])[1:3]\n",
    "                Y_TL_in, Y_BR_in = sorted([Y_TL1,Y_TL2, Y_BR1, Y_BR2])[1:3]\n",
    "                p1, p2, p3, p4  = map(Point, [[X_TL_in,Y_TL_in], [X_TL_in,Y_BR_in], [X_BR_in,Y_BR_in],[X_BR_in, Y_TL_in]]) \n",
    "                intersection = Polygon(p1, p2, p3, p4)            \n",
    "\n",
    "                #find polygon overlap\n",
    "                area_intersection = np.abs(intersection.area)\n",
    "                area_union = np.abs(id_polygon.area) + np.abs(matched_id_polygon.area) - area_intersection\n",
    "                overlap_fraction  = (area_intersection/area_union).evalf()\n",
    "            else:\n",
    "                overlap_fraction=0.            \n",
    "            if overlap_fraction > MAX_BBOX_OVERLAP:\n",
    "                bbox_dict[(row['id'],matched_id)] = [id_bb, matched_id_bb]\n",
    "                successful_matches.append((matched_id, overlap_fraction))\n",
    "            \n",
    "            # print('\\tMatching Id: ', matched_id,':', 'frame:',matched_id_min_frame,'overlap_fraction:', overlap_fraction)\n",
    "    if len(successful_matches) > 0:\n",
    "        successful_matched_id = sorted(successful_matches, key=lambda x: x[1])[-1][0]\n",
    "        print(row['id'], '-->Successful match to-->',successful_matched_id)\n",
    "        if row['id'] in potential_id_maps.keys():\n",
    "            potential_id_maps[successful_matched_id] = potential_id_maps[row['id']]\n",
    "        else:\n",
    "            potential_id_maps[successful_matched_id] = row['id']\n",
    "\n",
    "matched_ids  = list(potential_id_maps.keys())\n",
    "df_id_start_stop =  df_id_start_stop[~df_id_start_stop['id'].isin(matched_ids)].sort_values(by='id').reset_index(drop=True)\n",
    "printm(f'### Total ids after mapping: {df_id_start_stop.shape[0]}')\n",
    "\n",
    "printm(f'## Assign new ids to final set of postprocessed ids')\n",
    "new_to_old_id_map = df_id_start_stop['id'].to_dict()\n",
    "old_to_new_id_map = {v: k for k, v in new_to_old_id_map.items()}\n",
    "\n",
    "for matched_id in matched_ids:\n",
    "    old_to_new_id_map[matched_id] = old_to_new_id_map[potential_id_maps[matched_id]]\n",
    "    \n",
    "print(potential_id_maps)\n",
    "for removed_id in nonpersistent_ids_removed:\n",
    "    old_to_new_id_map[removed_id] = 10000\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201cf1ea-061d-48cc-832e-1164933cc2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# [0, 40, 15, 155, 43, 105, 44, 246, 97, 142]\n",
    "manual_bboxes = {\n",
    "    (10,38): ([2203,  445, 2504,  888], [2133,  451, 2490,  868]),\n",
    "    (38,163): ([2145,  462, 2498,  862], [2141,  458, 2498,  857]),\n",
    "    (163,185): ([2148,  462, 2500,  979], [2188,  455, 2517,  932]),\n",
    "    (185, 460): ([2216,  451, 2512,  889], [2151,  454, 2494,  904]),\n",
    "    (0, 40): ([1036,  249, 1391,  767], [1034,  271, 1295,  728]),\n",
    "    # (15, 155): ([2553,  351, 2876,  806], [2615,  335, 2886,  818]),\n",
    "    (120, 627):([2684,  449, 2945,  955], [2579,  463, 2956, 1028]),\n",
    "    (627, 805): ([2605,  451, 2908, 1008], [2590,  453, 2902,  998]),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485645ea-443b-4cc1-80d8-af83a7173402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [50, 1310, 120, 627, 805]\n",
    "# [10,38, 163,185, 460, 50, 1310, 120, 627, 627, 805]\n",
    "bbox_dict[(185, 460)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf8445f-4200-4444-8240-b9d46820c111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot manual bboxes on image\n",
    "# video_from_session = 'classinsight-cmu_05748A_ghc_4101_201901311630-front'\n",
    "video_from_session = 'classinsight-cmu_05748A_ghc_4101_201902051630-front'\n",
    "\n",
    "session_video_file = f'/mnt/ci-nas-classes/classinsight/2019S/video_backup/{video_from_session.split(\"-front\")[0]}/{video_from_session}.avi'\n",
    "frame_video = mmcv.VideoReader(session_video_file)[24000]\n",
    "frame_video.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7881f93e-3570-42f2-aad0-97a8d9a24981",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(frame_video)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff9402c-fb00-4d40-8dfb-e88781c298e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['#4c72b0', '#dd8452', '#55a868', '#c44e52', '#8172b3', '#937860', '#da8bc3', '#8c8c8c', '#ccb974', '#64b5cd']\n",
    "def hex_to_rgb(value):\n",
    "    value = value.lstrip('#')\n",
    "    lv = len(value)\n",
    "    return tuple(int(value[i:i + lv // 3], 16) for i in range(0, lv, lv // 3))\n",
    "\n",
    "\n",
    "# annotated_frame = cv2.cvtColor(deepcopy(frame_video), cv2.COLOR_BGR2RGB)\n",
    "annotated_frame = deepcopy(frame_video)\n",
    "prev_sid = 0\n",
    "color_idx = 0\n",
    "for idx, (sid1, sid2) in enumerate(manual_bboxes.keys()):\n",
    "    if not (sid1==prev_sid):\n",
    "        color_idx+=1\n",
    "        X_TL1, Y_TL1, X_BR1, Y_BR1 = manual_bboxes[(sid1,sid2)][0]\n",
    "    prev_sid=sid2\n",
    "    X_TL2, Y_TL2, X_BR2, Y_BR2 = manual_bboxes[(sid1,sid2)][1]\n",
    "    annotated_frame = cv2.rectangle(annotated_frame, (X_TL1, Y_TL1), (X_BR1, Y_BR1), hex_to_rgb(colors[color_idx]), 10)\n",
    "    annotated_frame = cv2.rectangle(annotated_frame, (X_TL2, Y_TL2), (X_BR2, Y_BR2), hex_to_rgb(colors[color_idx]), 10)\n",
    "    # plt.figure()\n",
    "    # print(sid1, sid2)\n",
    "    # plt.imshow(annotated_frame)\n",
    "\n",
    "cv2.imwrite(f'case_studies/plots/annotated_space_frame_v2.jpg', annotated_frame)\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(annotated_frame)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b868a4-bed1-4ff4-9fb2-5b776f5eeba1",
   "metadata": {},
   "source": [
    "# Create Visualization from each session to collect id ground truth "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cceb498-d9d4-40fd-8f37-afdd603ecd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_course = '05748A'\n",
    "sample_session_id = 'classinsight-cmu_05748A_ghc_4101_201902141630-front'\n",
    "session_tracking_cache_file = f\"{track_analysis_session_data}/{sample_session_id}.pb\"\n",
    "session_preprocessed_id_map_file = f\"{postprocessed_id_map_data_dir}/{sample_session_id}.pb\"\n",
    "session_frame_dir = f'{base_dir}/{sample_course}/{sample_session_id}'\n",
    "session_video_file = f'/mnt/ci-nas-classes/classinsight/2019S/video_backup/{sample_session_id.split(\"-front\")[0]}/{sample_session_id}.avi'\n",
    "session_frame_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991ea750-f727-4e12-b43e-4b2c8c90988e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tracking_new = pickle.load(open(session_tracking_cache_file,\"rb\")).transpose()\n",
    "old_to_new_id_map = pickle.load(open(session_preprocessed_id_map_file,\"rb\"))\n",
    "total_idxs = df_tracking_new.index.max()\n",
    "for old_id in old_to_new_id_map:\n",
    "    new_id = old_to_new_id_map[old_id]\n",
    "    if not new_id==10000:\n",
    "        new_id_col = f'N{new_id}'\n",
    "        if new_id_col not in df_tracking_new:\n",
    "            df_tracking_new[new_id_col] = None\n",
    "        df_tracking_new[new_id_col] =  df_tracking_new[old_id].where(~df_tracking_new[old_id].isnull(), df_tracking_new[old_id])\n",
    "    df_tracking_new = df_tracking_new.drop(old_id, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc2c11b-ce74-408e-8fd6-a4d49f30e193",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tracking_new.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4832bc-e694-4b5e-a4be-65f3598fe007",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_idxs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057a8a6d-c934-40b3-a712-e7c2e3879010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# old_to_new_id_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cd8987-5e21-4a63-93ad-da3b7e1556df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "col_start_stop_idxs = []\n",
    "for col in df_tracking_new.columns:\n",
    "    one_idxs = df_tracking_new.index[np.where(df_tracking_new[col]==1)[0]].values\n",
    "    col_start_stop_idxs.append([col, one_idxs.min(), one_idxs.max()])\n",
    "df_id_start_stop = pd.DataFrame(col_start_stop_idxs, columns=['id','min_idx','max_idx'])\n",
    "df_id_start_stop['total_idxs'] = df_id_start_stop['max_idx']-df_id_start_stop['min_idx']\n",
    "df_id_start_stop['id'] = df_id_start_stop['id'].apply(lambda x: int(x[1:]))\n",
    "df_id_start_stop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0837a3d1-1c7c-40b1-905a-13835c22b3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize=(20,15))\n",
    "for row_idx, row in df_id_start_stop.iterrows():\n",
    "    plt.axhline(y=row_idx, xmin=row['min_idx']/total_idxs,xmax=row['max_idx']/total_idxs)\n",
    "plt.yticks(range(df_id_start_stop.shape[0]), range(df_id_start_stop.shape[0]))\n",
    "plt.grid() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258326ec-f91d-4685-a622-73fd28f10161",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "session_frames = df_tracking_new.index.values.tolist()\n",
    "session_ids_covered = []\n",
    "selected_frames = []\n",
    "segments = []\n",
    "segment_half_size = 50\n",
    "for row_idx, row in df_id_start_stop.sort_values(by='total_idxs').iterrows():\n",
    "    id_start, id_stop = row['min_idx'],row['max_idx']\n",
    "    seg_mid = (id_start+id_stop)/2\n",
    "    seg_start, seg_end = max(seg_mid-segment_half_size, 0), min(seg_mid+segment_half_size, total_idxs)\n",
    "    is_id_covered = df_id_start_stop.apply(lambda row: (seg_end<=row['max_idx']) & (seg_start>=row['min_idx']),axis=1)\n",
    "    seg_ids_covered = df_id_start_stop[is_id_covered]['id']\n",
    "    new_ids_covered = [xr for xr in seg_ids_covered if xr not in session_ids_covered]\n",
    "    if len(new_ids_covered)>0:        \n",
    "        segment_frames = [xr for xr in session_frames if ((xr>=seg_start) and (xr<=seg_end))]\n",
    "        selected_frames+=segment_frames\n",
    "        segments.append((seg_start, seg_end, new_ids_covered, segment_frames))\n",
    "        session_ids_covered+=new_ids_covered\n",
    "\n",
    "sprint(segments)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d57418-1864-4e35-809b-da2421820246",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for given frame ranges get video frames and tracking results\n",
    "all_frames = mmcv.VideoReader(session_video_file)\n",
    "\n",
    "required_frame_ids = np.unique(sorted(selected_frames))\n",
    "frame_data_dict = {}\n",
    "\n",
    "for frame_idx, frame_img in enumerate(all_frames):\n",
    "    if (frame_idx in required_frame_ids) & (frame_idx%3==0):\n",
    "        frame_data_dict[frame_idx] = frame_img\n",
    "    if frame_idx%10000==0:\n",
    "        print(f\"Looped {frame_idx} images\")\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ae4995-3301-4ce1-803a-b6873775c8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_ROOT = '/home/prasoon/video_analysis/edusenseV2compute/compute/videoV3'\n",
    "run_config = {\n",
    "    'track_config':f'{SOURCE_ROOT}/configs/mmlab/ocsort_yolox_x_crowdhuman_mot17-private-half.py',\n",
    "    'track_checkpoint':f'{SOURCE_ROOT}/models/mmlab/ocsort_yolox_x_crowdhuman_mot17-private-half_20220813_101618-fe150582.pth',\n",
    "    'device':'cuda:1',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fe4935-5078-41ca-b37a-29bfe7ab8971",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(frame_data_dict.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9786394-0bf9-4640-86ba-4fdedd2d9e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_id_viz_dir = f'{id_viz_cache_root}/{sample_session_id}'\n",
    "os.makedirs(session_id_viz_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1cde26-0a73-4660-86a8-4c0a6df4cb89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if tracking_model:\n",
    "    printm(\"# Deleting Previous Model\")\n",
    "    del tracking_model\n",
    "tracking_model = init_tracking_model(run_config['track_config'],\n",
    "                                 run_config['track_checkpoint'],\n",
    "                                 device=run_config['device'])\n",
    "for seg_idx, (seg_start, seg_end, new_ids_covered, segment_frames) in enumerate(segments):\n",
    "    seg_video_id = f'S{seg_idx}_{int(seg_start)}_{int(seg_end)}_{\"_\".join(map(str,new_ids_covered))}'\n",
    "    match_cache_dir = f'{session_id_viz_dir}/{seg_video_id}'\n",
    "    match_video_file = f'{session_id_viz_dir}/{seg_video_id}.mp4'\n",
    "    if os.path.exists(match_video_file):\n",
    "        continue\n",
    "    print(match_video_file)\n",
    "    os.makedirs(match_cache_dir, exist_ok=True)\n",
    "    frame_num=0\n",
    "\n",
    "    for frame_idx in segment_frames:\n",
    "        frame_tracking_file = f\"{session_frame_dir}/{frame_idx}.pb\"\n",
    "        if os.path.exists(frame_tracking_file) and (frame_idx in frame_data_dict):\n",
    "            frame_file_out = os.path.join(match_cache_dir, f'{frame_num:06d}.jpg')\n",
    "            frame_num+=1\n",
    "            if os.path.exists(frame_file_out):\n",
    "                continue\n",
    "            frame_tracking_results = pickle.load(open(frame_tracking_file,\"rb\"))[1]\n",
    "            for person_idx in range(len(frame_tracking_results)):\n",
    "                old_id= int(frame_tracking_results[person_idx]['track_id'])\n",
    "                frame_tracking_results[person_idx]['track_id'] =old_to_new_id_map[old_id]\n",
    "            frame_img = deepcopy(frame_data_dict[frame_idx])\n",
    "            if len(frame_tracking_results)>0:\n",
    "                frame_tracking_results = {\n",
    "                    'track_bboxes':[np.array([[xr['track_id']]+xr['bbox'].tolist() for xr in frame_tracking_results])],\n",
    "                    'det_bboxes':[np.array([xr['bbox'].tolist() for xr in frame_tracking_results])]}\n",
    "                frame_track_img = tracking_model.show_result(\n",
    "                    frame_img,\n",
    "                    frame_tracking_results,\n",
    "                    thickness=5,\n",
    "                    font_scale=.5,\n",
    "                    score_thr=0.1,\n",
    "                    show=False,\n",
    "                    wait_time=int(1000. / 5),\n",
    "                    out_file=frame_file_out,\n",
    "                    backend='cv2')\n",
    "            else:\n",
    "                cv2.imwrite(frame_file_out,frame_img)\n",
    "    \n",
    "    #         break\n",
    "    # break\n",
    "    mmcv.frames2video(match_cache_dir, match_video_file, fps=5, fourcc='mp4v')\n",
    "    print(f\"Done for segment {seg_video_id}\")\n",
    "    # break\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05dd4477-a054-4342-9611-4df6e66e6953",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_viz_cache_root\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a398454-cb03-480a-9d8a-2f151a034554",
   "metadata": {},
   "source": [
    "# Run visualization code on all sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc50dbb6-3652-4358-b63a-2bcd727dcebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_ROOT = '/home/prasoon/video_analysis/edusenseV2compute/compute/videoV3'\n",
    "run_config = {\n",
    "    'track_config':f'{SOURCE_ROOT}/configs/mmlab/ocsort_yolox_x_crowdhuman_mot17-private-half.py',\n",
    "    'track_checkpoint':f'{SOURCE_ROOT}/models/mmlab/ocsort_yolox_x_crowdhuman_mot17-private-half_20220813_101618-fe150582.pth',\n",
    "    'device':'cuda:1',\n",
    "}\n",
    "\n",
    "for course_idx, course in enumerate(frame_file_data):\n",
    "    for session_idx, session_id in enumerate(frame_file_data[course]):\n",
    "        session_id_viz_dir = f'{id_viz_cache_root}/{session_id}'\n",
    "        if not os.path.exists(session_id_viz_dir):\n",
    "            \n",
    "            session_tracking_cache_file = f\"{track_analysis_session_data}/{session_id}.pb\"\n",
    "            session_preprocessed_id_map_file = f\"{postprocessed_id_map_data_dir}/{session_id}.pb\"\n",
    "            session_frame_dir = f'/mnt/ci-nas-cache/edulyzeV2/pose_face_gaze_emb/{course}/{session_id}'\n",
    "            session_video_file = f'/mnt/ci-nas-classes/classinsight/2019S/video_backup/{session_id.split(\"-front\")[0]}/{session_id}.avi'\n",
    "            printm(f'# {course_idx}-{course}, session:{session_idx}-{session_id}')\n",
    "            printm(\"## Get preprocessed tracking ids...\")\n",
    "            \n",
    "            df_tracking_new = pickle.load(open(session_tracking_cache_file,\"rb\")).transpose()\n",
    "            old_to_new_id_map = pickle.load(open(session_preprocessed_id_map_file,\"rb\"))\n",
    "            total_idxs = df_tracking_new.index.max()\n",
    "            for old_id in old_to_new_id_map:\n",
    "                new_id = old_to_new_id_map[old_id]\n",
    "                if not new_id==10000:\n",
    "                    new_id_col = f'N{new_id}'\n",
    "                    if new_id_col not in df_tracking_new:\n",
    "                        df_tracking_new[new_id_col] = None\n",
    "                    df_tracking_new[new_id_col] =  df_tracking_new[old_id].where(~df_tracking_new[old_id].isnull(), df_tracking_new[old_id])\n",
    "                df_tracking_new = df_tracking_new.drop(old_id, axis=1)\n",
    "\n",
    "            col_start_stop_idxs = []\n",
    "            for col in df_tracking_new.columns:\n",
    "                one_idxs = df_tracking_new.index[np.where(df_tracking_new[col]==1)[0]].values\n",
    "                col_start_stop_idxs.append([col, one_idxs.min(), one_idxs.max()])\n",
    "            df_id_start_stop = pd.DataFrame(col_start_stop_idxs, columns=['id','min_idx','max_idx'])\n",
    "            df_id_start_stop['total_idxs'] = df_id_start_stop['max_idx']-df_id_start_stop['min_idx']\n",
    "            df_id_start_stop['id'] = df_id_start_stop['id'].apply(lambda x: int(x[1:]))\n",
    "            \n",
    "            printm(f\"## Get segments to visualize from {df_tracking_new.shape[1]} tracking ids...\")\n",
    "            session_frames = df_tracking_new.index.values.tolist()\n",
    "            session_ids_covered = []\n",
    "            selected_frames = []\n",
    "            segments = []\n",
    "            segment_half_size = 50\n",
    "            for row_idx, row in df_id_start_stop.sort_values(by='total_idxs').iterrows():\n",
    "                id_start, id_stop = row['min_idx'],row['max_idx']\n",
    "                seg_mid = (id_start+id_stop)/2\n",
    "                seg_start, seg_end = max(seg_mid-segment_half_size, 0), min(seg_mid+segment_half_size, total_idxs)\n",
    "                is_id_covered = df_id_start_stop.apply(lambda row: (seg_end<=row['max_idx']) & (seg_start>=row['min_idx']),axis=1)\n",
    "                seg_ids_covered = df_id_start_stop[is_id_covered]['id']\n",
    "                new_ids_covered = [xr for xr in seg_ids_covered if xr not in session_ids_covered]\n",
    "                if len(new_ids_covered)>0:        \n",
    "                    segment_frames = [xr for xr in session_frames if ((xr>=seg_start) and (xr<=seg_end))]\n",
    "                    selected_frames+=segment_frames\n",
    "                    segments.append((seg_start, seg_end, new_ids_covered, segment_frames))\n",
    "                    session_ids_covered+=new_ids_covered\n",
    "            printm(f\"## Got {len(segments)} segments to visualize...\")\n",
    "\n",
    "            printm(f\"## Get video frames from session video file for segment frames...\")\n",
    "            all_frames = mmcv.VideoReader(session_video_file)\n",
    "            required_frame_ids = np.unique(sorted(selected_frames))\n",
    "            frame_data_dict = dict()\n",
    "            \n",
    "            for frame_idx, frame_img in enumerate(all_frames):\n",
    "                if (frame_idx in required_frame_ids) & (frame_idx%3==0):\n",
    "                    frame_data_dict[frame_idx] = frame_img\n",
    "                if frame_idx%1000==0:\n",
    "                    print(f\"Looped {frame_idx} images\")\n",
    "            printm(f\"## Got {len(frame_data_dict.keys())} video frames from session video file...\")\n",
    "\n",
    "            printm(f\"## Create segment videos with new tracking ids...\")\n",
    "            os.makedirs(session_id_viz_dir, exist_ok=True)\n",
    "            tracking_model = init_tracking_model(run_config['track_config'],\n",
    "                                             run_config['track_checkpoint'],\n",
    "                                             device=run_config['device'])\n",
    "            for seg_idx, (seg_start, seg_end, new_ids_covered, segment_frames) in enumerate(segments):\n",
    "                seg_video_id = f'S{seg_idx}_{int(seg_start)}_{int(seg_end)}_{\"_\".join(map(str,new_ids_covered))}'\n",
    "                match_cache_dir = f'{session_id_viz_dir}/{seg_video_id}'\n",
    "                match_video_file = f'{session_id_viz_dir}/{seg_video_id}.mp4'\n",
    "                if os.path.exists(match_video_file):\n",
    "                    continue\n",
    "                print(match_video_file)\n",
    "                os.makedirs(match_cache_dir, exist_ok=True)\n",
    "                frame_num=0\n",
    "            \n",
    "                for frame_idx in segment_frames:\n",
    "                    frame_tracking_file = f\"{session_frame_dir}/{frame_idx}.pb\"\n",
    "                    if os.path.exists(frame_tracking_file) and (frame_idx in frame_data_dict):\n",
    "                        frame_file_out = os.path.join(match_cache_dir, f'{frame_num:06d}.jpg')\n",
    "                        frame_num+=1\n",
    "                        if os.path.exists(frame_file_out):\n",
    "                            continue\n",
    "                        frame_tracking_results = pickle.load(open(frame_tracking_file,\"rb\"))[1]\n",
    "                        for person_idx in range(len(frame_tracking_results)):\n",
    "                            old_id= int(frame_tracking_results[person_idx]['track_id'])\n",
    "                            frame_tracking_results[person_idx]['track_id'] =old_to_new_id_map[old_id]\n",
    "                        frame_img = deepcopy(frame_data_dict[frame_idx])\n",
    "                        if len(frame_tracking_results)>0:\n",
    "                            frame_tracking_results = {\n",
    "                                'track_bboxes':[np.array([[xr['track_id']]+xr['bbox'].tolist() for xr in frame_tracking_results])],\n",
    "                                'det_bboxes':[np.array([xr['bbox'].tolist() for xr in frame_tracking_results])]}\n",
    "                            frame_track_img = tracking_model.show_result(\n",
    "                                frame_img,\n",
    "                                frame_tracking_results,\n",
    "                                thickness=5,\n",
    "                                font_scale=.5,\n",
    "                                score_thr=0.1,\n",
    "                                show=False,\n",
    "                                wait_time=int(1000. / 5),\n",
    "                                out_file=frame_file_out,\n",
    "                                backend='cv2')\n",
    "                        else:\n",
    "                            cv2.imwrite(frame_file_out,frame_img)\n",
    "                mmcv.frames2video(match_cache_dir, match_video_file, fps=5, fourcc='mp4v')\n",
    "                print(f\"Done for segment {seg_video_id}\")\n",
    "            del tracking_model\n",
    "            printm(f\"## Created Segment Visualization for session: {course_idx}-{course}, session:{session_idx}-{session_id} from {len(old_to_new_id_map.keys())} to {df_id_start_stop.shape[0]} ids\")\n",
    "        else:\n",
    "            printm(f\"## Segement visualization directory EXISTS for session: {course_idx}-{course}, session:{session_idx}-{session_id}\")\n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a688fb-6c62-4f33-9bd4-616d70db613b",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_video_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f0eea6-acad-433b-829c-7de6fd98e213",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
