{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f1bf94-25d4-4ed1-bddd-bc3309763692",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "from matplotlib import pyplot as plt, rcParams\n",
    "# import cv2\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style=\"white\", context=\"paper\")\n",
    "from cycler import cycler\n",
    "import os, sys\n",
    "import glob\n",
    "from datetime import datetime, timedelta\n",
    "from itertools import combinations, product\n",
    "import base64\n",
    "from PIL import Image\n",
    "from io import BytesIO as _BytesIO\n",
    "import requests\n",
    "import json\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from IPython.display import display, Markdown, Latex\n",
    "from sklearn.metrics import *\n",
    "import collections\n",
    "from copy import deepcopy\n",
    "import traceback\n",
    "from sympy import Point, Polygon\n",
    "from decorators import *\n",
    "from smartprint import smartprint as sprint\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.cluster import DBSCAN\n",
    "# import plotly\n",
    "# from pandas_profiling import ProfileReport\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "def printm(s): return display(Markdown(s))\n",
    "    \n",
    "SERVER_CACHE_DIR = '/mnt/ci-nas-cache/edulyzeV2/cache_compute_4/fixed_face'\n",
    "os.makedirs(SERVER_CACHE_DIR,exist_ok=True)\n",
    "\n",
    "track_analysis_meta_cache = f'{SERVER_CACHE_DIR}/analysis_tracking/meta_info'\n",
    "base_dir = '/mnt/ci-nas-cache/edulyzeV2/pose_face_gaze_emb_fixed_face/'\n",
    "\n",
    "track_analysis_session_data = f'{SERVER_CACHE_DIR}/analysis_tracking/session_tracking_info'\n",
    "os.makedirs(track_analysis_session_data,exist_ok=True)\n",
    "\n",
    "postprocessed_id_map_data_dir = f'{SERVER_CACHE_DIR}/analysis_tracking/processed_id_maps'\n",
    "os.makedirs(postprocessed_id_map_data_dir, exist_ok=True)\n",
    "\n",
    "emb_analysis_session_data = f'{SERVER_CACHE_DIR}/analysis_emb/session_emb_info_new'\n",
    "os.makedirs(emb_analysis_session_data,exist_ok=True)\n",
    "\n",
    "embmatched_id_raw_data_dir = f'{SERVER_CACHE_DIR}/analysis_emb/embmatched_id_raw'\n",
    "os.makedirs(embmatched_id_raw_data_dir,exist_ok=True)\n",
    "\n",
    "embmatched_id_map_data_dir = f'{SERVER_CACHE_DIR}/analysis_tracking/embmatched_id_maps'\n",
    "os.makedirs(embmatched_id_map_data_dir, exist_ok=True)\n",
    "\n",
    "cross_session_input_data_dir = f'{SERVER_CACHE_DIR}/analysis_emb/cross_session_input'\n",
    "os.makedirs(cross_session_input_data_dir, exist_ok=True)\n",
    "\n",
    "id_viz_cache_root = f'{SERVER_CACHE_DIR}/analysis_emb/session_matching_info'\n",
    "os.makedirs(id_viz_cache_root, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75185159-ce0e-439f-b41d-fba37829e865",
   "metadata": {},
   "source": [
    "## Get frame file data for all sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61657d24-cddc-4722-bbde-b99313f4c2e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "frame_file_data = {}\n",
    "for course_idx, course_dir in enumerate(glob.glob(f\"{base_dir}/*\")):\n",
    "    course_name = course_dir.split(\"/\")[-1]\n",
    "    course_cache_file = f\"{track_analysis_meta_cache}/{course_name}\"\n",
    "    if os.path.exists(course_cache_file):\n",
    "        frame_file_data[course_name] = pickle.load(open(course_cache_file,\"rb\"))\n",
    "        continue\n",
    "    frame_file_data[course_name]={}\n",
    "        \n",
    "    for session_idx, session_dir in enumerate(glob.glob(f\"{course_dir}/*\")):\n",
    "        session_name = session_dir.split(\"/\")[-1]\n",
    "        frame_file_data[course_name][session_name] = {}\n",
    "        frame_files = glob.glob(f\"{session_dir}/*\")\n",
    "        frame_file_names = [xr.split(\"/\")[-1] for xr in frame_files]\n",
    "        if 'end.pb' in frame_file_names:\n",
    "            frame_file_data[course_name][session_name]['is_completed']=True\n",
    "        else:\n",
    "            frame_file_data[course_name][session_name]['is_completed']=False            \n",
    "        frame_ids = [int(xr.split(\".\")[0]) for xr in frame_file_names if not (xr=='end.pb')]\n",
    "        frame_file_data[course_name][session_name]['frame_ids'] = sorted(frame_ids)\n",
    "        frame_file_data[course_name][session_name]['dir_location'] = session_dir\n",
    "        print(f\"Got metadata for course: {course_idx}-{course_name}, session:{session_idx}-{session_name}\")\n",
    "    pickle.dump(frame_file_data[course_name],open(course_cache_file,\"wb\")) \n",
    "        \n",
    "frame_file_data.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cf998f-dc47-447f-b1a8-14d55d69057c",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_filter_list = ['classinsight-cmu_05681A_ghc_4301_201905011630',\n",
    " 'classinsight-cmu_05681A_ghc_4301_201904171630',\n",
    " 'classinsight-cmu_05681A_ghc_4301_201902201630',\n",
    " 'classinsight-cmu_05681A_ghc_4301_201904101630',\n",
    " 'classinsight-cmu_05681A_ghc_4301_201901231630',\n",
    " 'classinsight-cmu_05418A_ghc_4102_201902251200',\n",
    " 'classinsight-cmu_05418A_ghc_4102_201904081200',\n",
    " 'classinsight-cmu_05418A_ghc_4102_201905011200',\n",
    " 'classinsight-cmu_05418A_ghc_4102_201904291200',\n",
    " 'classinsight-cmu_05418A_ghc_4102_201904011200',\n",
    " 'classinsight-cmu_05748A_ghc_4101_201902141630',\n",
    " 'classinsight-cmu_05748A_ghc_4101_201904021630',\n",
    " 'classinsight-cmu_05748A_ghc_4101_201902051630',\n",
    " 'classinsight-cmu_05748A_ghc_4101_201902281630',\n",
    " 'classinsight-cmu_05748A_ghc_4101_201903071630',\n",
    " 'classinsight-cmu_21127J_ghc_4102_201904230930',\n",
    " 'classinsight-cmu_21127J_ghc_4102_201903260930',\n",
    " 'classinsight-cmu_21127J_ghc_4102_201904160930',\n",
    " 'classinsight-cmu_21127J_ghc_4102_201904300930',\n",
    " 'classinsight-cmu_21127J_ghc_4102_201903190930',\n",
    " 'classinsight-cmu_05410A_ghc_4301_201904151500',\n",
    " 'classinsight-cmu_05410A_ghc_4301_201902251500',\n",
    " 'classinsight-cmu_05410A_ghc_4301_201904081500',\n",
    " 'classinsight-cmu_05410A_ghc_4301_201904221500',\n",
    " 'classinsight-cmu_05410A_ghc_4301_201902181500',\n",
    "                       \n",
    " 'classinsight-cmu_17214B_ph_a21_201902271030',\n",
    " 'classinsight-cmu_17214B_ph_a21_201903061030',\n",
    " 'classinsight-cmu_17214B_ph_a21_201904031030',\n",
    " 'classinsight-cmu_17214B_ph_a21_201904101030',\n",
    " 'classinsight-cmu_17214B_ph_a21_201904241030',\n",
    " 'classinsight-cmu_17214C_ph_225b_201904031130',\n",
    " 'classinsight-cmu_17214C_ph_225b_201904101130',\n",
    " 'classinsight-cmu_17214C_ph_225b_201904171130',\n",
    " 'classinsight-cmu_17214C_ph_225b_201904241130',\n",
    " 'classinsight-cmu_17214C_ph_225b_201905011130',\n",
    " 'classinsight-cmu_05410B_ghc_4211_201902111500',\n",
    " 'classinsight-cmu_05410B_ghc_4211_201903181500',\n",
    " 'classinsight-cmu_05410B_ghc_4211_201904081500',\n",
    " 'classinsight-cmu_05410B_ghc_4211_201904151500',\n",
    " 'classinsight-cmu_05410B_ghc_4211_201904221500',\n",
    " 'classinsight-cmu_05410B_ghc_4211_201901281500'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7383e4-c80d-417f-84f1-4452ad386c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "course='05748A'\n",
    "sessions = [xr for xr in session_filter_list if (course in xr)]\n",
    "sessions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72121535-6a23-4a92-918b-09a25083e9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get input for all sessions\n",
    "course_input_dict = {}\n",
    "for session in sessions:\n",
    "    session_input_file = f'{cross_session_input_data_dir}/{session}-front.pb'\n",
    "    course_input_dict[session] = pickle.load(open(session_input_file,\"rb\"))\n",
    "course_input_dict.keys()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc457e68-5f72-44ba-9165-5d4628a36e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "for session in sessions:\n",
    "    sprint(session, course_input_dict[session].keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6063a2d2-30f9-4718-b266-fbeee5bc9c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "course_input_dict[session][0].keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67827f52-6f48-4477-ac41-e51493384597",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(sessions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665b5928-e433-4d03-a96d-cf54435bc7d7",
   "metadata": {},
   "source": [
    "# Experiments with networkX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6267c6ed-7bcf-45c2-a4e1-5bdd6be7955a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get top 2 matches across all session pairs\n",
    "MATCH_THRESHOLD=0.4\n",
    "node_set = set()\n",
    "session_matches = {}\n",
    "for (sessionA, sessionB) in product(sorted(sessions)[:2], sorted(sessions)[:2]):\n",
    "    sessionA_key, sessionB_key = sessionA.split(\"_\")[-1][4:8], sessionB.split(\"_\")[-1][4:8]\n",
    "    if not (sessionA==sessionB):\n",
    "        # if sessionA not in session_matches:\n",
    "        # match session A and session B based on gaze clustering\n",
    "        match_scores = {}\n",
    "        for idA,idB in product(course_input_dict[sessionA].keys(), course_input_dict[sessionB].keys()):\n",
    "            gaze_embA, gaze_embB = course_input_dict[sessionA][idA]['gaze_emb'], course_input_dict[sessionB][idB]['gaze_emb']                \n",
    "            if idA not in match_scores:\n",
    "                match_scores[idA] = {}\n",
    "            if gaze_embA is None or gaze_embB is None:\n",
    "                match_scores[idA][idB] = np.inf\n",
    "            else:\n",
    "                match_distance = cdist(gaze_embA.reshape(1,-1), gaze_embB.reshape(1,-1))[0][0]\n",
    "                match_scores[idA][idB] = match_distance\n",
    "        df_match = pd.DataFrame(match_scores) \n",
    "        final_matches = []\n",
    "        for col in df_match.columns:\n",
    "            sessionB_matches = deepcopy(df_match[col]).sort_values().head(3).index.values\n",
    "            for match_id in sessionB_matches:\n",
    "                if match_scores[col][match_id]<MATCH_THRESHOLD:\n",
    "                    final_matches.append((f'{sessionA_key}_{col}', f'{sessionB_key}_{match_id}', match_scores[col][match_id]))\n",
    "                    node_set.add((sessionA_key, f'{sessionA_key}_{col}'))\n",
    "                    node_set.add((sessionB_key,f'{sessionB_key}_{match_id}'))\n",
    "        if sessionA_key not in session_matches:\n",
    "            session_matches[sessionA_key]={}\n",
    "        session_matches[sessionA_key][sessionB_key] = final_matches\n",
    "                \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf8075f-bc10-4aec-9bbe-81965dc75c92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "node_list = list(node_set)\n",
    "color_map=  {\n",
    "    '0205':\"red\",\n",
    "    '0214':\"blue\",\n",
    "    '0228':\"green\",\n",
    "    '0307':\"black\",\n",
    "    '0402':'brown'\n",
    "}\n",
    "node_color = [color_map[xr[0]] for xr in node_list]\n",
    "node_name = [xr[1] for xr in node_list]\n",
    "node_ids = np.arange(len(node_name))\n",
    "\n",
    "session_pos_val = ['0205', '0214', '0228', '0307', '0402']\n",
    "edge_labels = np.concatenate([session_matches[xr][yr] for xr,yr in product(session_matches.keys(), session_matches.keys()) if not (xr==yr)])\n",
    "edge_weights = [ round(1-float(xr[2]),2) for xr in edge_labels]\n",
    "weighted_edge_ids = [(node_name.index(xr[0]), node_name.index(xr[1]), round(1-float(xr[2]),2)) for xr in edge_labels]\n",
    "edge_ids = [(node_name.index(xr[0]), node_name.index(xr[1])) for xr in edge_labels]\n",
    "\n",
    "len(edge_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def97dd2-7251-477b-8d30-67e202512bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_pos = {node_ids[nr]:(session_pos_val.index(node_list[nr][0]), int(node_name[nr].split(\"_\")[1])*2) for nr in range(len(node_ids))}\n",
    "# node_pos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102ee908-ea19-4129-8c28-05002958bc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "plt.figure(figsize=(40,40))\n",
    "G = nx.DiGraph()\n",
    "G.add_nodes_from(node_ids)\n",
    "G.add_weighted_edges_from(weighted_edge_ids)\n",
    "labels = {node_ids[nr]:node_name[nr] for nr in range(len(node_ids))}\n",
    "\n",
    "\n",
    "nx.draw_networkx(G, pos = node_pos, labels = labels, arrows = True,\n",
    "                 node_shape = \"s\", node_size=1000,\n",
    "                 node_color = node_color,\n",
    "                 # edgelist=edge_ids, \n",
    "                 # edge_color=edge_weights,\n",
    "                 edgecolors = \"gray\")     #edges of the box of node\n",
    "nx.draw_networkx_edge_labels(G, pos = node_pos,\n",
    "                             edge_labels={edge_ids[nr]:edge_weights[nr] for nr in range(len(edge_weights))},\n",
    "                             font_color='black')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30edcf43-0d80-4a46-b1e6-b1a3ac6b8659",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_matches.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb2c893-d727-468b-828a-f371c46ba393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a filtered graph using only connections from one single edge\n",
    "def drawnodegraph(graph, nodename, info=False,weightbar=0):\n",
    "  # graph will be your networkx graph\n",
    "  # nodename will be the node that you want to focus on\n",
    "  # the default value for weightbar is 0, if increase the bar, rare relationship will be removed. Assuming no negative weights\n",
    "  temp = graph.copy(as_view=False) # make a temporary graph to avoid losing original ones\n",
    "  temp.remove_edges_from((e for e, w in nx.get_edge_attributes(temp,'weight').items() if w <= weightbar)) # remove rare relationhsip if weightbar is not 0\n",
    "  nodelist = list(temp.neighbors(n=nodename)) #generate the nodes that have relationship with our target node\n",
    "  nodelist.append(nodename) # add the target to the list\n",
    "  print(nodelist)\n",
    "  Sub = temp.subgraph(nodelist) # draw subgraph\n",
    "  \n",
    "  edges,weights = zip(*nx.get_edge_attributes(Sub,'weight').items())\n",
    "  # pos=nx.spring_layout(Sub,k=0.7,seed=42)\n",
    "  node_map = {nodename:7000} \n",
    "  nodesize=[node_map.get(node, 3500) for node in Sub.nodes()] # enlarge our target node\n",
    "  # val_map = {nodename:0.5714285714285714}\n",
    "  # nodecolor = [val_map.get(node, 0.25) for node in Sub.nodes()] # change the color of our target node\n",
    "  width = [w*2 for w in weights] # change the edge's width based on the weights of the edges\n",
    "  # nodecolor = \n",
    "  print({xr: node_pos[xr] for xr in nodelist})\n",
    "  nx.draw_networkx(Sub,\n",
    "                   pos = {xr: node_pos[xr] for xr in nodelist},\n",
    "                   # cmap=plt.get_cmap('viridis'),\n",
    "                   with_labels=True,\n",
    "                   labels = {xr:node_name[xr] for xr in nodelist}, \n",
    "                   node_color=[node_color[xr] for xr in Sub.nodes],\n",
    "                   node_size=nodesize,\n",
    "                   # edgelist=edges, \n",
    "                   edge_color=\"black\",\n",
    "                   #edge_cmap=plt.cm.Blues_r,\n",
    "                   style=\"solid\",\n",
    "                   font_color='white',\n",
    "                   font_size=12,\n",
    "                   width =width,\n",
    "                  connectionstyle=\"arc3,rad=0.05\")\n",
    "  plt.subplots_adjust(left=2, bottom=3.2, right=6, top=6)\n",
    "\n",
    "  # if info:\n",
    "  #   print(\"----------------------------------------\")\n",
    "  #   print(\"Density:\",nx.classes.function.density(Sub))\n",
    "  #   print(\"The information of the graph:\",nx.info(Sub))\n",
    "  #   print(\"----------------------------------------\")\n",
    "\n",
    "  return plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae67157-962f-4c91-b53f-2c540d80410b",
   "metadata": {},
   "outputs": [],
   "source": [
    "drawnodegraph(G, node_ids[5])\n",
    "drawnodegraph(G, node_ids[16])\n",
    "drawnodegraph(G, node_ids[22])\n",
    "drawnodegraph(G, node_ids[27])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b77d02-4aa7-440b-a1d5-db2bce8a0b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "drawnodegraph(G, node_ids[21])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6843136-334c-49df-9fa4-936fb4e2ed31",
   "metadata": {},
   "source": [
    "# Write algorithm for densest subnet of given size 5 in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0859e53-2371-474a-ac3c-14c7428c4f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a graph with networkx\n",
    "collect all nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761f1cbb-63a6-4e29-89ba-a8873e8fc7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_matches['0205']['0214']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4eda1c2-73eb-42d2-827c-3266b2499582",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_matches['0228']['0214']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbd67da-37b1-4a12-9db9-c364ffe4ef5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_matches['0214']['0228']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0abdc7-cf9d-439b-b47e-48db33f47a94",
   "metadata": {},
   "source": [
    "# Method 1: Sort in face sizes, select best of three based on least face_size differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bb698a-d62e-4d5a-9fac-697ef4b6bc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "MATCH_THRESHOLD=0.3\n",
    "final_matches = []\n",
    "for (sessionA, sessionB) in product(sorted(sessions), sorted(sessions)):\n",
    "    sessionA_key, sessionB_key = sessionA.split(\"_\")[-1][4:8], sessionB.split(\"_\")[-1][4:8]\n",
    "    if not (sessionA==sessionB):\n",
    "        # if sessionA not in session_matches:\n",
    "        # match session A and session B based on gaze clustering\n",
    "        match_scores_gaze = {}\n",
    "        match_scores_clu  = {}\n",
    "        for idA,idB in product(course_input_dict[sessionA].keys(), course_input_dict[sessionB].keys()):\n",
    "            \n",
    "            gaze_embA, gaze_embB = course_input_dict[sessionA][idA]['gaze_emb'], course_input_dict[sessionB][idB]['gaze_emb']                \n",
    "            clu_embA, clu_embB = course_input_dict[sessionA][idA]['cluster_emb'], course_input_dict[sessionB][idB]['cluster_emb']                \n",
    "            \n",
    "            if idA not in match_scores_gaze:\n",
    "                match_scores_gaze[idA] = {}\n",
    "            if idA not in match_scores_clu:\n",
    "                match_scores_clu[idA] = {}\n",
    "                \n",
    "            if gaze_embA is None or gaze_embB is None:\n",
    "                match_scores_gaze[idA][idB] = np.inf\n",
    "            else:\n",
    "                match_distance = cdist(gaze_embA.reshape(1,-1), gaze_embB.reshape(1,-1))[0][0]\n",
    "                match_scores_gaze[idA][idB] = match_distance\n",
    "\n",
    "            if clu_embA is None or clu_embB is None:\n",
    "                match_scores_clu[idA][idB] = np.inf\n",
    "            else:\n",
    "                match_distance = cdist(clu_embA.reshape(1,-1), clu_embB.reshape(1,-1))[0][0]\n",
    "                match_scores_clu[idA][idB] = match_distance\n",
    "        \n",
    "        df_match_gaze = pd.DataFrame(match_scores_gaze) \n",
    "        df_match_clu = pd.DataFrame(match_scores_clu) \n",
    "        gaze_cols = df_match_gaze.columns.values.tolist()\n",
    "        clu_cols = df_match_clu.columns.values.tolist()\n",
    "        all_cols = np.unique(gaze_cols+clu_cols)\n",
    "        for col in all_cols:\n",
    "            if col not in df_match_clu.columns:\n",
    "                df_match_clu[col] = np.inf\n",
    "            if col not in df_match_gaze.columns:\n",
    "                df_match_clu[col] = np.inf\n",
    "            sessionB_matches = deepcopy(df_match_clu[col]).sort_values().head(3).index.values.tolist() + \\\n",
    "                                deepcopy(df_match_gaze[col]).sort_values().head(3).index.values.tolist()\n",
    "            sessionB_matches = np.unique(sessionB_matches)\n",
    "            for match_id in sessionB_matches:\n",
    "                if (match_scores_clu[col][match_id]<MATCH_THRESHOLD) & (match_scores_gaze[col][match_id]<MATCH_THRESHOLD):\n",
    "                    col_face_area = course_input_dict[sessionA][col]['face_width_med'] * course_input_dict[sessionA][col]['face_height_med']\n",
    "                    match_face_area = course_input_dict[sessionB][match_id]['face_width_med'] * course_input_dict[sessionB][match_id]['face_height_med']\n",
    "                    rel_diff = np.abs(col_face_area-match_face_area)*100/min(col_face_area,match_face_area)\n",
    "                    final_matches.append((sessionA_key, sessionB_key, f'{sessionA_key}_{col}', f'{sessionB_key}_{match_id}', match_scores_gaze[col][match_id], match_scores_clu[col][match_id], col_face_area, match_face_area))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326f1b6c-d183-4e61-a8c4-2f4b00206b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_matches = pd.DataFrame(final_matches, columns=['sessionA','sessionB','idA','idB','match_score_gaze','match_score_clu','face_areaA','face_areaB'])\n",
    "df_final_matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfc1eda-e0a5-4f5d-b963-51bd3c7bd3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_matches[df_final_matches.idA=='0205_7'].sort_values(by='match_score_gaze')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ac8390-b4f0-45d9-a40d-9ac75361464f",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1,s2 = '0205','0214'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86af5982-7190-4ba5-9da3-6e9401793800",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pair_matches =df_final_matches\n",
    "# df_pair_matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ee7682-fe16-4655-9aa7-0f3d3f067d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pair_matches = df_pair_matches.sort_values(by=['face_areaA','face_areaB'],ascending=False)\n",
    "df_pair_matches['area_diff'] = np.abs(df_pair_matches['face_areaA'] - df_pair_matches['face_areaB'])*100/np.minimum(df_pair_matches['face_areaA'],df_pair_matches['face_areaB'])\n",
    "df_pair_matches.sort_values(by='idB')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fd5a05-e625-4c25-87c5-b4c0c93db202",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pair_matches[(df_pair_matches.match_score_gaze<0.2) & (df_pair_matches.match_score_clu<0.2) & (df_pair_matches.area_diff<20) & (np.minimum(df_pair_matches.face_areaA, df_pair_matches.face_areaB)>np.median(df_pair_matches.face_areaA))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9a2580-c9c1-48b4-ac55-f8ebc58c4264",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_matches = {}\n",
    "matched_idA, matched_idB = [],[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00263f9-d524-4b39-b395-b209036f0a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_match_1 = df_pair_matches[(df_pair_matches.match_score_gaze<0.2) & \n",
    "                                (df_pair_matches.match_score_clu<0.2) & \n",
    "                                (df_pair_matches.area_diff<20) & \n",
    "                                (np.minimum(df_pair_matches.face_areaA, df_pair_matches.face_areaB)>np.median(df_pair_matches.face_areaA))\n",
    "                                ].sort_values(by='match_score_gaze')\n",
    "sprint(best_match_1)\n",
    "for idx,row in best_match_1.iterrows():\n",
    "    if row['idA'] in matched_idA:\n",
    "        continue\n",
    "    elif row['idB'] in matched_idB:\n",
    "        continue\n",
    "    else:\n",
    "        id_matches[row['idA']] = row['idB']\n",
    "        matched_idA.append(row['idA'])\n",
    "        matched_idB.append(row['idB'])\n",
    "df_next_matches = df_pair_matches[(~df_pair_matches.idA.isin(matched_idA)) & (~df_pair_matches.idB.isin(matched_idB))]\n",
    "id_matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a251628-be54-4c0f-b469-981fada5b81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_next_matches = pd.merge(df_next_matches, df_next_matches.groupby('idA',as_index=False)['idB'].count(), on='idA',suffixes=('','_count'))\n",
    "df_next_matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b85d32f-efd8-4a16-a572-d59b6dfafe51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_single_matches = df_next_matches[df_next_matches.idB_count<=1]\n",
    "best_match_2 = df_single_matches[(df_single_matches.match_score_gaze<0.25) & \n",
    "                                (df_single_matches.match_score_clu<0.25) & \n",
    "                                (df_single_matches.area_diff<20) & \n",
    "                                (np.minimum(df_single_matches.face_areaA, df_single_matches.face_areaB)>np.median(df_pair_matches.face_areaA))\n",
    "                                ].sort_values(by='match_score_gaze')\n",
    "sprint(best_match_2)\n",
    "for idx,row in best_match_2.iterrows():\n",
    "    if row['idA'] in matched_idA:\n",
    "        continue\n",
    "    elif row['idB'] in matched_idB:\n",
    "        continue\n",
    "    else:\n",
    "        id_matches[row['idA']] = row['idB']\n",
    "        matched_idA.append(row['idA'])\n",
    "        matched_idB.append(row['idB'])\n",
    "df_next_matches = df_pair_matches[(~df_pair_matches.idA.isin(matched_idA)) & (~df_pair_matches.idB.isin(matched_idB))]\n",
    "id_matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467d4a92-92c9-4e8d-92c4-d0641c79860b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_next_matches = pd.merge(df_next_matches, df_next_matches.groupby('idB',as_index=False)['idA'].count(), on='idB',suffixes=('','_count'))\n",
    "df_next_matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05c3273-6cce-4051-bc89-8cd90525ce6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_match_3 = df_next_matches[(df_next_matches.idA_count<=1) & \n",
    "                                (df_next_matches.area_diff<20)].sort_values(by='match_score_gaze')\n",
    "sprint(best_match_3)\n",
    "for idx,row in best_match_3.iterrows():\n",
    "    if row['idA'] in matched_idA:\n",
    "        continue\n",
    "    elif row['idB'] in matched_idB:\n",
    "        continue\n",
    "    else:\n",
    "        id_matches[row['idA']] = row['idB']\n",
    "        matched_idA.append(row['idA'])\n",
    "        matched_idB.append(row['idB'])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88d4350-07b9-4b93-b9b3-b88ef3a5529f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_next_matches = df_pair_matches[(~df_pair_matches.idA.isin(matched_idA)) & (~df_pair_matches.idB.isin(matched_idB))]\n",
    "id_matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b526a18-9b3f-46e5-b857-a5d16c59c942",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_next_matches = pd.merge(df_next_matches, df_next_matches.groupby('idB',as_index=False)['idA'].count(), on='idB',suffixes=('','_count'))\n",
    "df_next_matches = pd.merge(df_next_matches, df_next_matches.groupby('idA',as_index=False)['idB'].count(), on='idA',suffixes=('','_count'))\n",
    "df_next_matches.sort_values(by='idA_count')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115f4efe-bdd8-451d-a31a-fb2baeac8df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_next_matches = pd.merge(df_next_matches, df_next_matches.groupby('idA',as_index=False).agg({'match_score_gaze':lambda x: 1.0 if (len(x)<2) else sorted(x)[1]-sorted(x)[0]}), on='idA',suffixes=('','_best_diff'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047f4ecd-ff81-4cfc-b2ec-a09dbf1e04db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_next_matches = pd.merge(df_next_matches, df_next_matches.groupby('idA',as_index=False).agg({'match_score_gaze':lambda x: sorted(x)[0]}), on='idA',suffixes=('','_min_match'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2a0784-bc80-422c-8e9f-f3104be64e9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3aebd1d-7a89-4074-a6b7-e369ecf61794",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_match_3 = df_next_matches[(df_next_matches.match_score_gaze<0.2) &\n",
    "                (df_next_matches.match_score_gaze_best_diff>0.05) &\n",
    "                (df_next_matches.match_score_gaze==df_next_matches.match_score_gaze_min_match)].sort_values(by='match_score_gaze')\n",
    "sprint(best_match_3)\n",
    "for idx,row in best_match_3.iterrows():\n",
    "    if row['idA'] in matched_idA:\n",
    "        continue\n",
    "    elif row['idB'] in matched_idB:\n",
    "        continue\n",
    "    else:\n",
    "        id_matches[row['idA']] = row['idB']\n",
    "        matched_idA.append(row['idA'])\n",
    "        matched_idB.append(row['idB'])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aefc179-18f9-4692-8c73-9fa751672d0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a139dd5-2bf5-4c57-9a05-28c1fd4c44d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_next_matches = df_pair_matches[(~df_pair_matches.idA.isin(matched_idA)) & (~df_pair_matches.idB.isin(matched_idB))]\n",
    "id_matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb5cf4d-0265-475f-9193-9931987e1a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_next_matches = df_next_matches[np.abs(df_next_matches['match_score_gaze']-df_next_matches['match_score_clu'])<0.05]\n",
    "df_next_matches = pd.merge(df_next_matches, df_next_matches.groupby('idB',as_index=False)['idA'].count(), on='idB',suffixes=('','_count'))\n",
    "df_next_matches = pd.merge(df_next_matches, df_next_matches.groupby('idA',as_index=False)['idB'].count(), on='idA',suffixes=('','_count'))\n",
    "df_next_matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40acf63-e6a0-4ff9-ab4c-be8d160b5768",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_next_matches = df_next_matches.sort_values(by=['face_areaA'],ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d94a99-72ac-462e-b2d4-6fb9fb8bf9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_next_matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab58b281-5974-4b48-b274-b6c09663544b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find matches where the best matches are not overlapping, and leave everything else\n",
    "id_matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf0859b-1ded-421d-9a1c-0d918f882ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sprint(s1,s2)\n",
    "sprint(id_matches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3bb168-bc45-42df-9fb9-8a5c909aa5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sprint(s1,s2)\n",
    "sprint(id_matches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7766eaf0-3429-47b2-8806-d746ad38d10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sprint(s1,s2)\n",
    "sprint(id_matches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e51c41c-205d-4057-b541-bde949f86271",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bd2316-f58c-45f8-93b8-e86fc2b1eca6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f23af2-5e5a-4f15-abc4-89ef58d77e37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62335ce-dfca-4947-b2ec-1234669ff674",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4918d245-3e9b-4ee0-ad12-6510fdfb21f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09453d5b-809e-489c-9f57-aaf55ac30d97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d3e98f-53e5-4ffb-86c5-c7e6d4027e72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255b4055-119d-4377-9002-03f655068309",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4391910-5317-44e7-a704-71af3a2bd462",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6cf5ccb8-bbf6-41cd-a4e2-0e3fc92bc38c",
   "metadata": {},
   "source": [
    "# Get visualization for all sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7387977b-9398-4bc0-88f4-8bddafd25d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_course = '05681A'\n",
    "sample_session_id = 'classinsight-cmu_05681A_ghc_4301_201904101630-front'\n",
    "session_tracking_cache_file = f\"{track_analysis_session_data}/{sample_session_id}.pb\"\n",
    "session_preprocessed_id_map_file = f\"{postprocessed_id_map_data_dir}/{sample_session_id}.pb\"\n",
    "session_frame_dir = f'{base_dir}/{sample_course}/{sample_session_id}'\n",
    "session_video_file = f'/mnt/ci-nas-classes/classinsight/2019S/video_backup/{sample_session_id.split(\"-front\")[0]}/{sample_session_id}.avi'\n",
    "session_frame_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a59222b-6b38-4a91-9e6b-3d0462dfe95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tracking_new = pickle.load(open(session_tracking_cache_file,\"rb\")).transpose()\n",
    "old_to_new_id_map = pickle.load(open(session_preprocessed_id_map_file,\"rb\"))\n",
    "total_idxs = df_tracking_new.index.max()\n",
    "for old_id in old_to_new_id_map:\n",
    "    new_id = old_to_new_id_map[old_id]\n",
    "    if not new_id==10000:\n",
    "        new_id_col = f'N{new_id}'\n",
    "        if new_id_col not in df_tracking_new:\n",
    "            df_tracking_new[new_id_col] = None\n",
    "        df_tracking_new[new_id_col] =  df_tracking_new[old_id].where(~df_tracking_new[old_id].isnull(), df_tracking_new[old_id])\n",
    "    df_tracking_new = df_tracking_new.drop(old_id, axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71afad94-22b6-4f13-8e84-41c90572f735",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e39af6-fd8d-4703-bffb-d8520845b69f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db945a5a-9f39-4fca-8034-776365031c76",
   "metadata": {},
   "source": [
    "# Run single session compilation for cross session id tracking input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c761f25a-a069-4161-a640-fc6c05b580b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = 'classinsight-cmu_05681A_ghc_4301_201904171630'\n",
    "\n",
    "# Get embedding and gaze information for all frames for all sessions (Run if needed, commented out for now)?\n",
    "session_emb_info = pickle.load(open(f'{emb_analysis_session_data}/{session}-front.pb','rb'))\n",
    "session_id_map = pickle.load(open(f\"{postprocessed_id_map_data_dir}/{session}-front.pb\",\"rb\"))\n",
    "df_session_eligible_pairs = pd.read_csv(f\"{embmatched_id_map_data_dir}/{session}-front.csv\")\n",
    "session_video_file = f'/mnt/ci-nas-classes/classinsight/2019S/video_backup/{session}/{session}-front.avi'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f46f46-8851-441f-b78d-c969ff3d960e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace raw ids with mapped ids after postprocessing for both sessions\n",
    "session_emb_info = {\n",
    "    xr:{\n",
    "        session_id_map[yr]:session_emb_info[xr][yr] \n",
    "            for yr in session_emb_info[xr] if not (session_id_map[yr]==10000)} for xr in session_emb_info}\n",
    "\n",
    "# Correct new ids with dict from eligible pairs\n",
    "eligible_id_map_dict = {}\n",
    "for id_pair in df_session_eligible_pairs.id_pair.values:\n",
    "    (id1, id2) = eval(id_pair)\n",
    "    print(id1, id2)\n",
    "    if id2 in eligible_id_map_dict:\n",
    "        eligible_id_map_dict[id1] = eligible_id_map_dict[id2]\n",
    "        print(f\"{id1}--> {eligible_id_map_dict[id2]}\")\n",
    "    # elif id1 in eligible_id_map_dict:\n",
    "    #     eligible_id_map_dict[id2] = eligible_id_map_dict[id1]\n",
    "    #     print(f\"{id2}--> {eligible_id_map_dict[id1]}\")\n",
    "    else:\n",
    "        eligible_id_map_dict[id2] = id1\n",
    "        print(f\"{id2}--> {id1}\")\n",
    "\n",
    "sprint(eligible_id_map_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9276d228-c09b-4b53-847d-b0e6eeb67ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct new ids with dict from eligible pairs\n",
    "eligible_id_map_dict = {}\n",
    "for id_pair in df_session_eligible_pairs.id_pair.values:\n",
    "    (id1, id2) = eval(id_pair)\n",
    "    print(id1, id2)\n",
    "    if id2 in eligible_id_map_dict:\n",
    "        eligible_id_map_dict[id1] = eligible_id_map_dict[id2]\n",
    "    else:\n",
    "        eligible_id_map_dict[id2] = id1\n",
    "        print(f\"{id2}--> {id1}\")\n",
    "sprint(eligible_id_map_dict)\n",
    "\n",
    "for key in eligible_id_map_dict:\n",
    "    key_value = eligible_id_map_dict[key]\n",
    "    if key_value in eligible_id_map_dict.keys():\n",
    "        eligible_id_map_dict[key] = eligible_id_map_dict[key_value]\n",
    "sprint(eligible_id_map_dict)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69c351d-7b28-43d0-87f1-9dfabe76298c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# arrange info as per tracking id across both sessions\n",
    "\n",
    "gaze_info = {}\n",
    "emb_info = {}\n",
    "bbox_info = {}\n",
    "face_info = {}\n",
    "for frame_number in session_emb_info:\n",
    "    for trackId_old in session_emb_info[frame_number]:\n",
    "        trackId = trackId_old if (trackId_old not in eligible_id_map_dict.keys()) else eligible_id_map_dict[trackId_old]\n",
    "        if trackId not in gaze_info:\n",
    "            gaze_info[trackId] = []\n",
    "            emb_info[trackId]=[]\n",
    "            bbox_info[trackId] = []\n",
    "            face_info[trackId] = []\n",
    "        # get  gaze info\n",
    "        try:\n",
    "            id_bbox = session_emb_info[frame_number][trackId]['bbox']\n",
    "            bbox_info[trackId].append([frame_number]+list(id_bbox))\n",
    "\n",
    "            id_face = session_emb_info[frame_number][trackId]['face'][0]\n",
    "            face_info[trackId].append([frame_number]+list(id_face))\n",
    "            \n",
    "            pitch, roll, yaw= session_emb_info[frame_number][trackId]['rvec'][0]\n",
    "            pitch, roll, yaw=np.rad2deg(pitch), np.rad2deg(roll), np.rad2deg(yaw)\n",
    "            gaze_sx, gaze_sy, gaze_ex, gaze_ey = session_emb_info[frame_number][trackId]['gaze_2d'][0].flatten()\n",
    "            gaze_info[trackId].append([frame_number, pitch, roll, yaw, gaze_sx, gaze_sy, gaze_ex, gaze_ey])\n",
    "            face_emb = session_emb_info[frame_number][trackId]['face_embedding'].tolist()\n",
    "            emb_info[trackId].append([frame_number]+face_emb)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "for id in gaze_info:\n",
    "    gaze_info[id] = pd.DataFrame(gaze_info[id], columns=['frame','pitch','roll','yaw','gaze_sx', 'gaze_sy', 'gaze_ex', 'gaze_ey']).set_index('frame')\n",
    "    emb_info[id] =pd.DataFrame(emb_info[id], columns=['frame']+np.arange(512).tolist()).set_index('frame')\n",
    "    bbox_info[id] = pd.DataFrame(bbox_info[id], columns=['frame']+np.arange(5).tolist()).set_index('frame')\n",
    "    face_info[id] = pd.DataFrame(face_info[id], columns=['frame']+np.arange(15).tolist()).set_index('frame')\n",
    "\n",
    "sprint({xr:(gaze_info[xr].shape[0],emb_info[xr].shape[0], face_info[xr].shape[0], bbox_info[xr].shape[0]) for xr in emb_info})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cd2204-2d5d-4534-8ef6-7d3de7746283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get gaze based embeddings\n",
    "MAX_GAZE_DEVIATION_DEG = 30\n",
    "# MAX_EMBEDDING_FRAMES = 1000\n",
    "MIN_EMBEDDING_FRAMES = 100\n",
    "\n",
    "gaze_based_embeddings = {}\n",
    "for sid in emb_info.keys():\n",
    "    #filter correct frames\n",
    "    frames = gaze_info[sid][\n",
    "        (gaze_info[sid].yaw.abs()<MAX_GAZE_DEVIATION_DEG) & \n",
    "        (gaze_info[sid].pitch.abs()<MAX_GAZE_DEVIATION_DEG) & \n",
    "        (gaze_info[sid].roll.abs()<MAX_GAZE_DEVIATION_DEG)].index.values\n",
    "\n",
    "    num_frames = len(frames)\n",
    "    if (num_frames<MIN_EMBEDDING_FRAMES):\n",
    "        sprint(f\"Not sufficient frames to match {sid}:{len(frames)}\")\n",
    "        continue\n",
    "    #get id embeddings    \n",
    "    median_emb = np.median(emb_info[sid].loc[frames],axis=0)\n",
    "    sprint(f\"Got gaze embedding for {sid}.\")\n",
    "    gaze_based_embeddings[sid]=median_emb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8818fa93-2c81-4fb3-9f49-10d06d72e538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get cluster based embeddings\n",
    "CLU_EPS = 0.4\n",
    "CLU_MIN_PTS = 100\n",
    "np.random.seed(42)\n",
    "cluster_based_emb = {}\n",
    "for sid in emb_info:\n",
    "    emb_clu = DBSCAN(min_samples=CLU_MIN_PTS, eps=CLU_EPS)\n",
    "    emb_clu.fit(emb_info[sid].values)\n",
    "    if max(emb_clu.labels_)<0:\n",
    "        sprint(f\"All frames are outliers, not proceeding with id {sid}\")\n",
    "        continue\n",
    "    best_cluster_id = pd.Series(emb_clu.labels_[emb_clu.labels_>=0]).value_counts().index[0]\n",
    "    frames = emb_info[sid].iloc[emb_clu.labels_==best_cluster_id].index.values\n",
    "    cluster_based_emb[sid] = np.median(emb_info[sid].loc[frames],axis=0)\n",
    "    sprint(f\"Got cluster embedding for {sid}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f45925-3e20-4d8b-8186-ec5d920deed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_id_info = {}\n",
    "for sid in face_info:\n",
    "    sample_df =deepcopy(bbox_info[sid])\n",
    "    \n",
    "    sample_df['bbox_width'] = sample_df[2]-sample_df[0]\n",
    "    sample_df['bbox_height'] = sample_df[3]-sample_df[1]\n",
    "    bbox_width_med, bbox_height_med = sample_df['bbox_width'].median(), sample_df['bbox_height'].median()\n",
    "    bbox_width_iqd = sample_df['bbox_width'].quantile(0.75) - sample_df['bbox_width'].quantile(0.25)\n",
    "    bbox_height_iqd = sample_df['bbox_height'].quantile(0.75) - sample_df['bbox_height'].quantile(0.25)\n",
    "\n",
    "    sample_df =deepcopy(face_info[sid])\n",
    "    sample_df['face_width'] = sample_df[2]-sample_df[0]\n",
    "    sample_df['face_height'] = sample_df[3]-sample_df[1]\n",
    "    sample_df['face_height'] = sample_df[3]-sample_df[1]\n",
    "    sample_df['face_x'] = (sample_df[2]+sample_df[0]) / 2\n",
    "    sample_df['face_y'] = (sample_df[3]+sample_df[1]) / 2\n",
    "    \n",
    "    face_width_med, face_height_med = sample_df['face_width'].median(), sample_df['face_height'].median()\n",
    "    face_width_iqd = sample_df['face_width'].quantile(0.75) - sample_df['face_width'].quantile(0.25)\n",
    "    face_height_iqd = sample_df['face_height'].quantile(0.75) - sample_df['face_height'].quantile(0.25)\n",
    "    \n",
    "    face_x_med, face_y_med = sample_df['face_x'].median(), sample_df['face_x'].median()\n",
    "    face_x_iqd = sample_df['face_x'].quantile(0.75) - sample_df['face_x'].quantile(0.25)\n",
    "    face_y_iqd = sample_df['face_y'].quantile(0.75) - sample_df['face_y'].quantile(0.25)\n",
    "\n",
    "    session_id_info[sid] = dict(bbox_width_med=bbox_width_med, bbox_height_med=bbox_height_med,bbox_width_iqd=bbox_width_iqd, bbox_height_iqd=bbox_height_iqd,\n",
    "                         face_width_med=face_width_med, face_height_med=face_height_med, face_width_iqd=face_width_iqd, face_height_iqd=face_height_iqd,\n",
    "                         face_x_med=face_x_med, face_y_med=face_y_med, face_x_iqd=face_x_iqd, face_y_iqd=face_y_iqd, \n",
    "                         cluster_emb = cluster_based_emb.get(sid, None), \n",
    "                         gaze_emb=gaze_based_embeddings.get(sid, None))\n",
    "\n",
    "sprint(face_width_med, face_width_iqd, face_height_med, face_height_iqd, face_x_med, face_x_iqd, face_y_med, face_y_iqd)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7760eedd-b392-4f44-8f72-e5b533942829",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917ff6b9-8242-4198-9aa6-0b2815aa20fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720628bb-c168-44ad-af10-e8439fbab885",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_scores = {}\n",
    "for idA in matching_info_dictB:\n",
    "    match_scores[idA] = {}\n",
    "    for idB in matching_info_dictB[idA]:\n",
    "        match_matrix = matching_info_dictB[idA][idB]['match_matrix']\n",
    "        match_distance = np.median(np.median(match_matrix,axis=1))\n",
    "        match_scores[idA][idB] = match_distance\n",
    "\n",
    "df_matching = pd.DataFrame(match_scores)\n",
    "\n",
    "#--------\n",
    "fig, axn = plt.subplots(1,1,figsize=(20,10))\n",
    "sns.heatmap(df_matching.round(2), annot=True,ax=axn,cmap='bone_r')\n",
    "for gtA in map(int, gt_map):\n",
    "    for gtB in map(int, gt_map[str(gtA)]):\n",
    "        if (gtA>=0) and (gtB>=0):\n",
    "            if (gtA in df_matching.columns) and (gtB in df_matching.index):\n",
    "                locA, locB = df_matching.columns.get_loc(gtA), df_matching.index.get_loc(gtB)\n",
    "                axn.add_patch(Rectangle((locA, locB), 1, 1, fill=False, edgecolor='red', lw=4))\n",
    "\n",
    "for locA in range(df_matching.shape[1]):\n",
    "    locBs = df_matching.iloc[:,locA].argsort()[:3]\n",
    "    for locB in locBs:\n",
    "        axn.add_patch(Rectangle((locA, locB), 1, 1, fill=False, edgecolor='blue', lw=1))\n",
    "\n",
    "\n",
    "axn.set_xlabel(f\"Session A: {sessionA}\",fontsize=16)\n",
    "axn.set_ylabel(f\"Session B: {sessionB}\",fontsize=16)\n",
    "plt.savefig(f'plots/Method2b_{course}_{sessionA.split(\"_\")[-1]}_{sessionB.split(\"_\")[-1]}.png',dpi=400,bbox_inches='tight')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
