{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f1bf94-25d4-4ed1-bddd-bc3309763692",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "from matplotlib import pyplot as plt, rcParams\n",
    "# import cv2\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style=\"white\", context=\"paper\")\n",
    "from cycler import cycler\n",
    "import os, sys\n",
    "import glob\n",
    "from datetime import datetime, timedelta\n",
    "from itertools import combinations, product\n",
    "import base64\n",
    "from PIL import Image\n",
    "from io import BytesIO as _BytesIO\n",
    "import requests\n",
    "import json\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from IPython.display import display, Markdown, Latex\n",
    "from sklearn.metrics import *\n",
    "import collections\n",
    "from copy import deepcopy\n",
    "import traceback\n",
    "from sympy import Point, Polygon\n",
    "from decorators import *\n",
    "from smartprint import smartprint as sprint\n",
    "from scipy.spatial.distance import cdist\n",
    "import cv2\n",
    "from sklearn.cluster import DBSCAN\n",
    "# import plotly\n",
    "# from pandas_profiling import ProfileReport\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "def printm(s): return display(Markdown(s))\n",
    "    \n",
    "SERVER_CACHE_DIR = '/mnt/ci-nas-cache/edulyzeV2/cache_compute_4/fixed_face'\n",
    "os.makedirs(SERVER_CACHE_DIR,exist_ok=True)\n",
    "\n",
    "track_analysis_meta_cache = f'{SERVER_CACHE_DIR}/analysis_tracking/meta_info'\n",
    "base_dir = '/mnt/ci-nas-cache/edulyzeV2/pose_face_gaze_emb_fixed_face/'\n",
    "\n",
    "track_analysis_session_data = f'{SERVER_CACHE_DIR}/analysis_tracking/session_tracking_info'\n",
    "os.makedirs(track_analysis_session_data,exist_ok=True)\n",
    "\n",
    "postprocessed_id_map_data_dir = f'{SERVER_CACHE_DIR}/analysis_tracking/processed_id_maps'\n",
    "os.makedirs(postprocessed_id_map_data_dir, exist_ok=True)\n",
    "\n",
    "emb_analysis_session_data = f'{SERVER_CACHE_DIR}/analysis_emb/session_emb_info_new'\n",
    "os.makedirs(emb_analysis_session_data,exist_ok=True)\n",
    "\n",
    "pose_analysis_session_data = f'{SERVER_CACHE_DIR}/analysis_pose/session_pose_info'\n",
    "os.makedirs(pose_analysis_session_data,exist_ok=True)\n",
    "\n",
    "embmatched_id_raw_data_dir = f'{SERVER_CACHE_DIR}/analysis_emb/embmatched_id_raw'\n",
    "os.makedirs(embmatched_id_raw_data_dir,exist_ok=True)\n",
    "\n",
    "embmatched_id_map_data_dir = f'{SERVER_CACHE_DIR}/analysis_tracking/embmatched_id_maps_new'\n",
    "os.makedirs(embmatched_id_map_data_dir, exist_ok=True)\n",
    "\n",
    "in_session_median_embeddings_data_dir = f'{SERVER_CACHE_DIR}/analysis_tracking/in_session_median_embeddings'\n",
    "os.makedirs(in_session_median_embeddings_data_dir, exist_ok=True)\n",
    "\n",
    "in_session_cluster_embeddings_data_dir = f'{SERVER_CACHE_DIR}/analysis_tracking/in_session_cluster_embeddings'\n",
    "os.makedirs(in_session_cluster_embeddings_data_dir, exist_ok=True)\n",
    "\n",
    "id_viz_cache_root = f'{SERVER_CACHE_DIR}/analysis_tracking/session_matching_info'\n",
    "os.makedirs(id_viz_cache_root, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565327ad-9d75-4198-a740-74e64061e373",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_filter_list = [\n",
    " #    'classinsight-cmu_05681A_ghc_4301_201905011630',\n",
    " # 'classinsight-cmu_05681A_ghc_4301_201904171630',\n",
    " # 'classinsight-cmu_05681A_ghc_4301_201902201630',\n",
    " # 'classinsight-cmu_05681A_ghc_4301_201904101630',\n",
    " # 'classinsight-cmu_05681A_ghc_4301_201901231630',\n",
    " # 'classinsight-cmu_05418A_ghc_4102_201902251200',\n",
    " # 'classinsight-cmu_05418A_ghc_4102_201904081200',\n",
    " # 'classinsight-cmu_05418A_ghc_4102_201905011200',\n",
    " # 'classinsight-cmu_05418A_ghc_4102_201904291200',\n",
    " # 'classinsight-cmu_05418A_ghc_4102_201904011200',\n",
    " 'classinsight-cmu_05748A_ghc_4101_201902141630',\n",
    " 'classinsight-cmu_05748A_ghc_4101_201904021630',\n",
    " 'classinsight-cmu_05748A_ghc_4101_201902051630',\n",
    " 'classinsight-cmu_05748A_ghc_4101_201902281630',\n",
    " 'classinsight-cmu_05748A_ghc_4101_201903071630',\n",
    " # 'classinsight-cmu_21127J_ghc_4102_201904230930',\n",
    " # 'classinsight-cmu_21127J_ghc_4102_201903260930',\n",
    " # 'classinsight-cmu_21127J_ghc_4102_201904160930',\n",
    " # 'classinsight-cmu_21127J_ghc_4102_201904300930',\n",
    " # 'classinsight-cmu_21127J_ghc_4102_201903190930',\n",
    " # 'classinsight-cmu_05410A_ghc_4301_201904151500',\n",
    " # 'classinsight-cmu_05410A_ghc_4301_201902251500',\n",
    " # 'classinsight-cmu_05410A_ghc_4301_201904081500',\n",
    " # 'classinsight-cmu_05410A_ghc_4301_201904221500',\n",
    " # 'classinsight-cmu_05410A_ghc_4301_201902181500',\n",
    "                       \n",
    " 'classinsight-cmu_17214B_ph_a21_201902271030',\n",
    " 'classinsight-cmu_17214B_ph_a21_201903061030',\n",
    " 'classinsight-cmu_17214B_ph_a21_201904031030',\n",
    " 'classinsight-cmu_17214B_ph_a21_201904101030',\n",
    " 'classinsight-cmu_17214B_ph_a21_201904241030',\n",
    " 'classinsight-cmu_17214C_ph_225b_201903201130',\n",
    " 'classinsight-cmu_17214C_ph_225b_201904101130',\n",
    " 'classinsight-cmu_17214C_ph_225b_201904171130',\n",
    " 'classinsight-cmu_17214C_ph_225b_201904241130',\n",
    " 'classinsight-cmu_17214C_ph_225b_201905011130',\n",
    " # 'classinsight-cmu_05410B_ghc_4211_201902111500',\n",
    " # 'classinsight-cmu_05410B_ghc_4211_201903181500',\n",
    " # 'classinsight-cmu_05410B_ghc_4211_201904081500',\n",
    " # 'classinsight-cmu_05410B_ghc_4211_201904151500',\n",
    " # 'classinsight-cmu_05410B_ghc_4211_201904221500',\n",
    " # 'classinsight-cmu_05410B_ghc_4211_201901281500'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6410b40-d069-4aab-9000-36e08b0a0763",
   "metadata": {},
   "source": [
    "## Get embedding and gaze information for all frames for all sessions (Run if needed, commented out for now)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75185159-ce0e-439f-b41d-fba37829e865",
   "metadata": {},
   "source": [
    "## Get frame file data for all sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61657d24-cddc-4722-bbde-b99313f4c2e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "frame_file_data = {}\n",
    "for course_idx, course_dir in enumerate(glob.glob(f\"{base_dir}/*\")):\n",
    "    course_name = course_dir.split(\"/\")[-1]\n",
    "    course_cache_file = f\"{track_analysis_meta_cache}/{course_name}\"\n",
    "    if os.path.exists(course_cache_file):\n",
    "        frame_file_data[course_name] = pickle.load(open(course_cache_file,\"rb\"))\n",
    "        continue\n",
    "    frame_file_data[course_name]={}\n",
    "        \n",
    "    for session_idx, session_dir in enumerate(glob.glob(f\"{course_dir}/*\")):\n",
    "        session_name = session_dir.split(\"/\")[-1]\n",
    "        frame_file_data[course_name][session_name] = {}\n",
    "        frame_files = glob.glob(f\"{session_dir}/*\")\n",
    "        frame_file_names = [xr.split(\"/\")[-1] for xr in frame_files]\n",
    "        if 'end.pb' in frame_file_names:\n",
    "            frame_file_data[course_name][session_name]['is_completed']=True\n",
    "        else:\n",
    "            frame_file_data[course_name][session_name]['is_completed']=False            \n",
    "        frame_ids = [int(xr.split(\".\")[0]) for xr in frame_file_names if not (xr=='end.pb')]\n",
    "        frame_file_data[course_name][session_name]['frame_ids'] = sorted(frame_ids)\n",
    "        frame_file_data[course_name][session_name]['dir_location'] = session_dir\n",
    "        print(f\"Got metadata for course: {course_idx}-{course_name}, session:{session_idx}-{session_name}\")\n",
    "    pickle.dump(frame_file_data[course_name],open(course_cache_file,\"wb\")) \n",
    "        \n",
    "        \n",
    "frame_file_data.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36bfd90-7cd5-401a-9f6e-ea20e180ab96",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_kps = frame_data[0]['keypoints']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9b9af3-b6e5-43f2-b1dd-e81dd02bdc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# openpose_body_markers = ['nose', 'neck', 'right shoulder', 'right elbow', 'right wrist',\n",
    "#         'left shoulder', 'left elbow', 'left wrist', 'right hip', 'right knee',\n",
    "#         'right ankle', 'left hip', 'left knee', 'left ankle', 'right eye',\n",
    "#         'left eye', 'right ear', 'left ear'\n",
    "#             ]\n",
    "openpose25_body_markers = ['nose', 'neck', 'right shoulder', 'right elbow', 'right wrist',\n",
    "        'left shoulder', 'left elbow', 'left wrist', 'hip','right hip', 'right knee',\n",
    "        'right ankle', 'left hip', 'left knee', 'left ankle', 'right eye',\n",
    "        'left eye', 'right ear', 'left ear']\n",
    "\n",
    "posenet_body_markers =[\n",
    "        'nose', 'left eye', 'right eye', 'left ear', 'right ear',\n",
    "        'left shoulder', 'right shoulder', 'left elbow', 'right elbow',\n",
    "        'left wrist', 'right wrist', 'left hip', 'right hip', 'left knee',\n",
    "        'right knee', 'left ankle', 'right ankle'\n",
    "    ]\n",
    "\n",
    "def posenet_to_openpose(keypoints):\n",
    "    openpose_keypoints = np.zeros((26,3))\n",
    "    for i in range(keypoints.shape[0]):\n",
    "        openpose_index = openpose25_body_markers.index(posenet_body_markers[i])\n",
    "        # print(posenet_body_markers[i], openpose_index)\n",
    "        openpose_keypoints[openpose_index]= keypoints[i]\n",
    "    openpose_keypoints[1] = (openpose_keypoints[2] + openpose_keypoints[5])/2\n",
    "    openpose_keypoints[8] = (openpose_keypoints[9] + openpose_keypoints[12])/2\n",
    "    return openpose_keypoints.flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175bca1f-4c9b-4e2f-8a54-71db0ac3aaf5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "keypoints = posenet_to_openpose(dummy_kps)\n",
    "keypoints, keypoints.flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f970cb72-c8ad-4d77-a484-e821a01ef50e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#verification for point conversion\n",
    "# import cv2\n",
    "# keypoints = [\n",
    "#     (100, 200),  # Nose\n",
    "#     (120, 180),  # Neck\n",
    "#     (80, 170),   # Right Shoulder\n",
    "#     (150, 170),  # Left Shoulder\n",
    "#     (90, 250),   # Right Elbow\n",
    "#     (160, 240),  # Left Elbow\n",
    "#     (100, 320),  # Right Wrist\n",
    "#     (170, 310),  # Left Wrist\n",
    "#     # Add more keypoints as needed\n",
    "# ]\n",
    "\n",
    "# Define the skeleton connections (pairs of keypoints)\n",
    "skeleton = [\n",
    "    # Upper body\n",
    "    (0, 1),   # Nose to Neck\n",
    "    (1, 2),   # Neck to Right Shoulder\n",
    "    (1, 5),   # Neck to Left Shoulder\n",
    "    (2, 3),   # Right Shoulder to Right Elbow\n",
    "    (3, 4),   # Right Elbow to Right Wrist\n",
    "    (5, 6),   # Left Shoulder to Left Elbow\n",
    "    (6, 7),   # Left Elbow to Left Wrist\n",
    "\n",
    "    # Lower body\n",
    "    (1, 8),   # Neck to Right Hip\n",
    "    (1, 11),  # Neck to Left Hip\n",
    "    (8, 9),   # Right Hip to Right Knee\n",
    "    (9, 10),  # Right Knee to Right Ankle\n",
    "    (11, 12), # Left Hip to Left Knee\n",
    "    (12, 13), # Left Knee to Left Ankle\n",
    "\n",
    "    # Connect upper body to lower body\n",
    "    (8, 12),  # Right Hip to Left Hip\n",
    "\n",
    "    # Additional connections for body parts\n",
    "    (0, 14),  # Nose to Right Eye\n",
    "    (0, 15),  # Nose to Left Eye\n",
    "    (14, 16), # Right Eye to Right Ear\n",
    "    (15, 17)  # Left Eye to Left Ear\n",
    "]\n",
    "openpose_skeleton_25 = [\n",
    "    # Upper body\n",
    "    (0, 1),   # Nose to Neck\n",
    "    (1, 2),   # Neck to Right Shoulder\n",
    "    (2, 3),   # Right Shoulder to Right Elbow\n",
    "    (3, 4),   # Right Elbow to Right Wrist\n",
    "    (1, 5),   # Neck to Left Shoulder\n",
    "    (5, 6),   # Left Shoulder to Left Elbow\n",
    "    (6, 7),   # Left Elbow to Left Wrist\n",
    "\n",
    "    # Lower body\n",
    "    (1, 8),   # Neck to Right Hip\n",
    "    (8, 9),   # Right Hip to Right Knee\n",
    "    (9, 10),  # Right Knee to Right Ankle\n",
    "    (1, 11),  # Neck to Left Hip\n",
    "    (11, 12), # Left Hip to Left Knee\n",
    "    (12, 13), # Left Knee to Left Ankle\n",
    "\n",
    "    # Connect upper body to lower body\n",
    "    (8, 12),  # Right Hip to Left Hip\n",
    "\n",
    "    # Additional connections for face and ears\n",
    "    (14, 15), # Right Eye to Left Eye\n",
    "    (15, 17), # Left Eye to Left Ear\n",
    "    (14, 16), # Right Eye to Right Ear\n",
    "\n",
    "    # Additional connections for optional keypoints\n",
    "    (10, 19), # Right Knee to Right Big Toe\n",
    "    (19, 20), # Right Big Toe to Right Small Toe\n",
    "    (20, 21), # Right Small Toe to Right Heel\n",
    "\n",
    "    (13, 22), # Left Knee to Left Big Toe\n",
    "    (22, 23), # Left Big Toe to Left Small Toe\n",
    "    (23, 24), # Left Small Toe to Left Heel\n",
    "\n",
    "    # Background (used for image segmentation)\n",
    "    (0, 25)  # Nose to Background\n",
    "]\n",
    "\n",
    "BODY_25_KEYPOINT_CONNECTIONS = [\n",
    "    (8, 9),\n",
    "    (8, 12),  \n",
    "    (1, 2), \n",
    "    (2, 3),\n",
    "    (3, 4),\n",
    "    (1, 5),\n",
    "    (5, 6),\n",
    "    (6, 7),\n",
    "    (1, 0),  \n",
    "    (0, 15),\n",
    "    (15, 17),\n",
    "    (0, 16),\n",
    "    (16, 18),\n",
    "    (2, 12),\n",
    "    (9, 5),\n",
    "    (12, 14), \n",
    "    (14, 16),\n",
    "    (16, 20),\n",
    "    (20, 22),\n",
    "    (9, 11),\n",
    "    (11, 13),\n",
    "    (13, 15),\n",
    "    (15, 19),\n",
    "    (19, 21)\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "keypoints = np.array([[1849, 194, 1], #0\n",
    "                      [1861, 235, 1], #1\n",
    "                      [1813, 241, 1], #2\n",
    "                      [1772, 312, 1], #3\n",
    "                      [1813, 265, 1], #4\n",
    "                      [1914, 224, 1], #5\n",
    "                      [1955, 307, 1], #6\n",
    "                      [1920, 383, 1], #7\n",
    "                      [1855, 377, 1], #8\n",
    "                      [1814, 371, 1], #9\n",
    "                      [1766, 424, 1], #10\n",
    "                      [0, 0, 0], #11\n",
    "                      [1896, 383, 1], #12\n",
    "                      [1855, 465, 1], #13\n",
    "                      [0, 0, 0], #14\n",
    "                      [1831, 177, 1], #15\n",
    "                      [1855, 171, 1], #16\n",
    "                      [0, 0, 0], #17\n",
    "                      [1873, 171, 1], #18\n",
    "                      [0, 0, 0], #0\n",
    "                      [0, 0, 0], \n",
    "                      [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0]])\n",
    "# Create an image canvas\n",
    "image = np.zeros((2160,3840, 3), dtype=np.uint8)\n",
    "\n",
    "# Draw keypoints\n",
    "for idx, (x, y, p) in enumerate(keypoints):\n",
    "    if (x>0):\n",
    "        cv2.circle(image, (int(x), int(y)), 5, (0, 0, 255), -1)\n",
    "        # image = cv2.putText(image, (int(x), int(y)), 5, (0, 0, 255), -1)\n",
    "\n",
    "# Draw skeleton lines\n",
    "for start, end in openpose_skeleton_25:\n",
    "    x1, y1 = keypoints[start][:2]\n",
    "    x1, y1 = int(x1), int(y1)\n",
    "    x2, y2 = keypoints[end][:2]\n",
    "    x2, y2 = int(x2), int(y2)\n",
    "    if (x1>0) & (x2>0):\n",
    "        cv2.line(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "# Display the image with skeleton\n",
    "plt.imshow(cv2.cvtColor(image[0:500,1600:2000,:], cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')\n",
    "plt.show()#0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7d1e90-05ba-456c-8b4e-bc1f16ebd5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from edusense_scripts.process_frame import process_frame\n",
    "from edusense_scripts.centroidtracker import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e800bdf5-fbe4-4741-86f1-13fdb69f2fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.exists(pose_analysis_session_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0d3c5e-7b9d-4919-888b-26526be404f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# writing a generic loop to get edusense inference info from all courses in frame file data\n",
    "logger = logging.getLogger()\n",
    "for course_idx, course in enumerate(frame_file_data):\n",
    "    for session_idx, session_id in enumerate(frame_file_data[course]):\n",
    "        if session_id.split(\"-front\")[0] not in session_filter_list:\n",
    "            print(f\"Session {session_id} not in session filter list, skipping...\")\n",
    "            continue\n",
    "        session_pose_cache_file = f\"{pose_analysis_session_data}/{session_id}.pb\"\n",
    "        # try:\n",
    "        if not os.path.exists(session_pose_cache_file):\n",
    "            st_time = time.time()\n",
    "            session_dir = frame_file_data[course][session_id]['dir_location']\n",
    "            frame_ids = frame_file_data[course][session_id]['frame_ids']\n",
    "            session_frame_info = {}\n",
    "            ctracker = CentroidTracker()\n",
    "            for frame_id in frame_ids:\n",
    "                frame_number, frame_data = pickle.load(open(f'{session_dir}/{frame_id}.pb','rb'))\n",
    "                edusense_frame_data = {'people':[\n",
    "                    {\n",
    "                        'track_id':int(person_info['track_id']),\n",
    "                        'bbox': person_info['bbox'] if 'bbox' in person_info else None,\n",
    "                        'rvec': person_info['rvec'] if 'rvec' in person_info else None,\n",
    "                        'face_bb': person_info['face'] if 'face' in person_info else None,\n",
    "                        'gaze_2d':person_info['gaze_2d'] if 'gaze_2d' in person_info else None,\n",
    "                        'face_embedding': person_info['face_embedding'] if 'face_embedding' in person_info else None,\n",
    "                        'posenet_pose': person_info['keypoints'] if 'keypoints' in person_info else None,\n",
    "                        'body': posenet_to_openpose(person_info['keypoints']) if 'keypoints' in person_info else None,\n",
    "                    } for person_info in frame_data\n",
    "                ]\n",
    "                }\n",
    "                try:\n",
    "                    frame_data = process_frame(frame_id, edusense_frame_data, ctracker,logger)\n",
    "                    session_frame_info[frame_id] = frame_data\n",
    "                except:\n",
    "                    print(f\"Error in frame:{session_id}-{frame_id}\")\n",
    "                    session_frame_info[frame_id] = edusense_frame_data\n",
    "                # session_frame_info[frame_id] = frame_data\n",
    "                \n",
    "            pickle.dump(session_frame_info, open(session_pose_cache_file,'wb'))\n",
    "            print(f\"Got pose info for session: {course_idx}-{course}, session:{session_idx}-{session_id} in {round(time.time()-st_time,2)} secs...\")\n",
    "        else:\n",
    "            ...\n",
    "            print(f\"FILE EXISTS: pose info for session: {course_idx}-{course}, session:{session_idx}-{session_id}\")\n",
    "        # except:\n",
    "        #     print(f\"ERROR: Unable to get session emb for: {course_idx}-{course}, session:{session_idx}-{session_id}\")\n",
    "        #     unfinished_sessions.append((course, session_id))\n",
    "        #     print(traceback.format_exc())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004699a4-ed26-4bc3-bf2d-23814c079711",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "frame_data['people'][0]['inference'], frame_data['people'][0]['face_bb'][0][:4]+frame_data['people'][0]['bbox'][:4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b778431-74e0-4e5e-8c72-17ec0a43ba09",
   "metadata": {},
   "outputs": [],
   "source": [
    "len([1.56673743e+03, 1.71408447e+02, 1.00000000e+00, 1.59161292e+03,\n",
    "        2.14375366e+02, 1.00000000e+00, 1.53960034e+03, 2.07591125e+02,\n",
    "        1.00000000e+00, 1.50341772e+03, 2.75433594e+02, 1.00000000e+00,\n",
    "        1.49437207e+03, 3.16139099e+02, 1.00000000e+00, 1.64362549e+03,\n",
    "        2.21159607e+02, 1.00000000e+00, 1.63457983e+03, 3.07093445e+02,\n",
    "        1.00000000e+00, 1.55769177e+03, 3.20661926e+02, 1.00000000e+00,\n",
    "        1.53055469e+03, 3.43276062e+02, 1.00000000e+00, 1.45366663e+03,\n",
    "        4.06595764e+02, 1.00000000e+00, 1.50341772e+03, 5.15143677e+02,\n",
    "        1.00000000e+00, 1.59839722e+03, 3.47798889e+02, 1.00000000e+00,\n",
    "        1.59387439e+03, 4.11118591e+02, 1.00000000e+00, 1.58935156e+03,\n",
    "        5.28712219e+02, 1.00000000e+00, 1.56221460e+03, 1.62362793e+02,\n",
    "        1.00000000e+00, 1.58030591e+03, 1.62362793e+02, 1.00000000e+00,\n",
    "        1.55316895e+03, 1.57839966e+02, 1.00000000e+00, 1.60744287e+03,\n",
    "        1.57839966e+02, 1.00000000e+00])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5b0533-d295-488f-8598-3068889081b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get gaze info on looking down and get gaze marker for looking front.\n",
    "\n",
    "#For looking front, yaw-angle is less than +/- 30%\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
