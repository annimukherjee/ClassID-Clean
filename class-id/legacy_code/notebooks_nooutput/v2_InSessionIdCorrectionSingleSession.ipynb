{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f1bf94-25d4-4ed1-bddd-bc3309763692",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "from matplotlib import pyplot as plt, rcParams\n",
    "# import cv2\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style=\"white\", context=\"paper\")\n",
    "from cycler import cycler\n",
    "import os, sys\n",
    "import glob\n",
    "from datetime import datetime, timedelta\n",
    "from itertools import combinations, product\n",
    "import base64\n",
    "from PIL import Image\n",
    "from io import BytesIO as _BytesIO\n",
    "import requests\n",
    "import json\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from IPython.display import display, Markdown, Latex\n",
    "from sklearn.metrics import *\n",
    "import collections\n",
    "from copy import deepcopy\n",
    "import traceback\n",
    "from sympy import Point, Polygon\n",
    "from decorators import *\n",
    "from smartprint import smartprint as sprint\n",
    "from scipy.spatial.distance import cdist\n",
    "# import plotly\n",
    "# from pandas_profiling import ProfileReport\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "def printm(s): return display(Markdown(s))\n",
    "    \n",
    "SERVER_CACHE_DIR = '/mnt/ci-nas-cache/edulyzeV2/cache_compute_4/fixed_face'\n",
    "os.makedirs(SERVER_CACHE_DIR,exist_ok=True)\n",
    "\n",
    "track_analysis_meta_cache = f'{SERVER_CACHE_DIR}/analysis_tracking/meta_info'\n",
    "base_dir = '/mnt/ci-nas-cache/edulyzeV2/pose_face_gaze_emb_fixed_face/'\n",
    "\n",
    "track_analysis_session_data = f'{SERVER_CACHE_DIR}/analysis_tracking/session_tracking_info'\n",
    "os.makedirs(track_analysis_session_data,exist_ok=True)\n",
    "\n",
    "postprocessed_id_map_data_dir = f'{SERVER_CACHE_DIR}/analysis_tracking/processed_id_maps'\n",
    "os.makedirs(postprocessed_id_map_data_dir, exist_ok=True)\n",
    "\n",
    "embmatched_id_map_data_dir = f'{SERVER_CACHE_DIR}/analysis_tracking/embmatched_id_maps'\n",
    "os.makedirs(embmatched_id_map_data_dir, exist_ok=True)\n",
    "\n",
    "in_session_median_embeddings_data_dir = f'{SERVER_CACHE_DIR}/analysis_tracking/in_session_median_embeddings'\n",
    "os.makedirs(in_session_median_embeddings_data_dir, exist_ok=True)\n",
    "\n",
    "in_session_cluster_embeddings_data_dir = f'{SERVER_CACHE_DIR}/analysis_tracking/in_session_cluster_embeddings'\n",
    "os.makedirs(in_session_cluster_embeddings_data_dir, exist_ok=True)\n",
    "\n",
    "id_viz_cache_root = f'{SERVER_CACHE_DIR}/analysis_tracking/session_matching_info'\n",
    "os.makedirs(id_viz_cache_root, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952b2f7f-0ea6-447c-a9a6-dfd498c42f14",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "session = 'classinsight-cmu_05748A_ghc_4101_201902141630'\n",
    "course = '05748A'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175722ec-8f9f-4b40-85a8-d41ad38e787b",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_frame_dir = f'{base_dir}/{course}/{session}-front'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6410b40-d069-4aab-9000-36e08b0a0763",
   "metadata": {},
   "source": [
    "## Get embedding and gaze information for all frames for all sessions (Run if needed, commented out for now)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75185159-ce0e-439f-b41d-fba37829e865",
   "metadata": {},
   "source": [
    "## Get frame file data for all sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61657d24-cddc-4722-bbde-b99313f4c2e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "frame_file_data = {}\n",
    "for course_idx, course_dir in enumerate(glob.glob(f\"{base_dir}/*\")):\n",
    "    course_name = course_dir.split(\"/\")[-1]\n",
    "    course_cache_file = f\"{track_analysis_meta_cache}/{course_name}\"\n",
    "    if os.path.exists(course_cache_file):\n",
    "        frame_file_data[course_name] = pickle.load(open(course_cache_file,\"rb\"))\n",
    "        continue\n",
    "    frame_file_data[course_name]={}\n",
    "        \n",
    "    for session_idx, session_dir in enumerate(glob.glob(f\"{course_dir}/*\")):\n",
    "        session_name = session_dir.split(\"/\")[-1]\n",
    "        frame_file_data[course_name][session_name] = {}\n",
    "        frame_files = glob.glob(f\"{session_dir}/*\")\n",
    "        frame_file_names = [xr.split(\"/\")[-1] for xr in frame_files]\n",
    "        if 'end.pb' in frame_file_names:\n",
    "            frame_file_data[course_name][session_name]['is_completed']=True\n",
    "        else:\n",
    "            frame_file_data[course_name][session_name]['is_completed']=False            \n",
    "        frame_ids = [int(xr.split(\".\")[0]) for xr in frame_file_names if not (xr=='end.pb')]\n",
    "        frame_file_data[course_name][session_name]['frame_ids'] = sorted(frame_ids)\n",
    "        frame_file_data[course_name][session_name]['dir_location'] = session_dir\n",
    "        print(f\"Got metadata for course: {course_idx}-{course_name}, session:{session_idx}-{session_name}\")\n",
    "    pickle.dump(frame_file_data[course_name],open(course_cache_file,\"wb\")) \n",
    "        \n",
    "        \n",
    "frame_file_data.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0d3c5e-7b9d-4919-888b-26526be404f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# writing a generic loop to get embedding info from all courses in frame file data\n",
    "emb_analysis_session_data = f'{SERVER_CACHE_DIR}/analysis_emb/session_emb_info'\n",
    "os.makedirs(emb_analysis_session_data,exist_ok=True)\n",
    "\n",
    "for course_idx, course in enumerate(frame_file_data):\n",
    "    for session_idx, session_id in enumerate(frame_file_data[course]):\n",
    "        session_emb_cache_file = f\"{emb_analysis_session_data}/{session_id}.pb\"\n",
    "        try:\n",
    "            if not os.path.exists(session_emb_cache_file):\n",
    "                session_dir = frame_file_data[course][session_id]['dir_location']\n",
    "                frame_ids = frame_file_data[course][session_id]['frame_ids']\n",
    "                session_emb_info = {}\n",
    "                for frame_id in frame_ids:\n",
    "                    frame_number, frame_data = pickle.load(open(f'{session_dir}/{frame_id}.pb','rb'))\n",
    "                    frame_emb_info = {int(person_info['track_id']):{\n",
    "                        'bbox': person_info['bbox'] if 'bbox' in person_info else None,\n",
    "                        'rvec': person_info['rvec'] if 'rvec' in person_info else None,\n",
    "                        'gaze_2d':person_info['gaze_2d'] if 'gaze_2d' in person_info else None,\n",
    "                        'face_embedding': person_info['face_embedding'] if 'face_embedding' in person_info else None,\n",
    "                    } for person_info in frame_data}\n",
    "                    session_emb_info[frame_id] = frame_emb_info\n",
    "                pickle.dump(session_emb_info, open(session_emb_cache_file,'wb'))\n",
    "                print(f\"Got emb info for session: {course_idx}-{course}, session:{session_idx}-{session_id}\")\n",
    "            else:\n",
    "                ...\n",
    "                print(f\"FILE EXISTS: emb info for session: {course_idx}-{course}, session:{session_idx}-{session_id}\")\n",
    "        except:\n",
    "            print(f\"ERROR: Unable to get session emb for: {course_idx}-{course}, session:{session_idx}-{session_id}\")\n",
    "            unfinished_sessions.append((course, session_id))\n",
    "            print(traceback.format_exc())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f44fe4-ecfb-4eb9-bf25-a04eb23e641a",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_emb_info = pickle.load(open(f'{SERVER_CACHE_DIR}/analysis_emb/session_emb_info/{session}-front.pb','rb'))\n",
    "session_id_map = pickle.load(open(f\"{postprocessed_id_map_data_dir}/{session}-front.pb\",\"rb\"))\n",
    "df_tracking_new = pickle.load(open(f\"{track_analysis_session_data}/{session}-front.pb\",\"rb\")).transpose()\n",
    "\n",
    "# Replace raw ids with mapped ids for given session\n",
    "session_emb_info = {\n",
    "    xr:{\n",
    "        session_id_map[yr]:session_emb_info[xr][yr] \n",
    "            for yr in session_emb_info[xr] if not (session_id_map[yr]==10000)} for xr in session_emb_info}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc4d4f6-26fd-4fcb-a363-2e0aa4e101d8",
   "metadata": {},
   "source": [
    "### Get id start stop for given session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003a4f0e-a807-48bd-86c6-ba4f30ffe5b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_idxs = df_tracking_new.index.max()\n",
    "for old_id in session_id_map:\n",
    "    new_id = session_id_map[old_id]\n",
    "    if not new_id==10000:\n",
    "        new_id_col = f'N{new_id}'\n",
    "        if new_id_col not in df_tracking_new:\n",
    "            df_tracking_new[new_id_col] = None\n",
    "        df_tracking_new[new_id_col] =  df_tracking_new[old_id].where(~df_tracking_new[old_id].isnull(), df_tracking_new[old_id])\n",
    "    df_tracking_new = df_tracking_new.drop(old_id, axis=1)\n",
    "\n",
    "col_start_stop_idxs = []\n",
    "for col in df_tracking_new.columns:\n",
    "    one_idxs = df_tracking_new.index[np.where(df_tracking_new[col]==1)[0]].values\n",
    "    col_start_stop_idxs.append([col, one_idxs.min(), one_idxs.max()])\n",
    "df_id_start_stop = pd.DataFrame(col_start_stop_idxs, columns=['id','min_idx','max_idx'])\n",
    "df_id_start_stop['total_idxs'] = df_id_start_stop['max_idx']-df_id_start_stop['min_idx']\n",
    "df_id_start_stop['id'] = df_id_start_stop['id'].apply(lambda x: int(x[1:]))\n",
    "df_id_start_stop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42b4d6b-b295-4f86-8dc8-32ef15ad55b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize=(20,15))\n",
    "for row_idx, row in df_id_start_stop.iterrows():\n",
    "    plt.axhline(y=row_idx, xmin=row['min_idx']/total_idxs,xmax=row['max_idx']/total_idxs)\n",
    "plt.yticks(range(df_id_start_stop.shape[0]), range(df_id_start_stop.shape[0]))\n",
    "plt.grid() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03202d1-f1e8-4129-8805-713f4aefbc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arrange info as per tracking id across both sessions\n",
    "# pitch, roll, yaw= session_emb_info[0][9]['rvec'][0]\n",
    "gaze_info = {}\n",
    "emb_info = {}\n",
    "bbox_info = {}\n",
    "\n",
    "for frame_number in session_emb_info:\n",
    "    for trackId in session_emb_info[frame_number]:\n",
    "        if trackId not in gaze_info:\n",
    "            gaze_info[trackId] = []\n",
    "            emb_info[trackId]=[]\n",
    "            bbox_info[trackId] = []\n",
    "        # get  gaze info\n",
    "        try:\n",
    "            id_bbox = session_emb_info[frame_number][trackId]['bbox']\n",
    "            bbox_info[trackId].append([frame_number]+list(id_bbox))\n",
    "            pitch, roll, yaw= session_emb_info[frame_number][trackId]['rvec'][0]\n",
    "            pitch, roll, yaw=np.rad2deg(pitch), np.rad2deg(roll), np.rad2deg(yaw)\n",
    "            gaze_sx, gaze_sy, gaze_ex, gaze_ey = session_emb_info[frame_number][trackId]['gaze_2d'][0].flatten()\n",
    "            gaze_info[trackId].append([frame_number, pitch, roll, yaw, gaze_sx, gaze_sy, gaze_ex, gaze_ey])\n",
    "            face_emb = session_emb_info[frame_number][trackId]['face_embedding'].tolist()\n",
    "            emb_info[trackId].append([frame_number]+face_emb)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "for id in gaze_info:\n",
    "    gaze_info[id] = pd.DataFrame(gaze_info[id], columns=['frame','pitch','roll','yaw','gaze_sx', 'gaze_sy', 'gaze_ex', 'gaze_ey']).set_index('frame')\n",
    "    emb_info[id] =pd.DataFrame(emb_info[id], columns=['frame']+np.arange(512).tolist()).set_index('frame')\n",
    "    bbox_info[id] = pd.DataFrame(bbox_info[id], columns=['frame']+np.arange(5).tolist()).set_index('frame')\n",
    "\n",
    "len(gaze_info.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c296f535-9459-42c5-a022-eb2a430e51be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sprint({xr:(gaze_info[xr].shape[0],emb_info[xr].shape[0], bbox_info[xr].shape[0]) for xr in emb_info})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b3dab3-3c43-4b10-bc10-bc5ffec02b9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_id_start_stop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195efc5b-0b56-440b-9166-e13697fc62f1",
   "metadata": {},
   "source": [
    "## Use spectral clustering to get clean set of embeddings, calculate their centroid, and then evaluate distance for non overlapping ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e866dcca-50c6-456e-a823-47af5b510a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "EPS = 0.4\n",
    "MIN_PTS = 100\n",
    "DISTANCE_THRESHOLD = 0.2\n",
    "OVERLAP_THRESHOLD = 0.8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7eaad0-e3b3-463c-8852-7d1d8f6ad75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.random.seed(42)\n",
    "clustered_median_emb = {}\n",
    "for id in emb_info:\n",
    "    emb_clu = DBSCAN(min_samples=MIN_PTS, eps=EPS)\n",
    "    emb_clu.fit(emb_info[id].values)\n",
    "    if max(emb_clu.labels_)<0:\n",
    "        sprint(f\"All frames are outliers, not proceeding with id {id}\")\n",
    "        continue\n",
    "    best_cluster_id = pd.Series(emb_clu.labels_[emb_clu.labels_>=0]).value_counts().index[0]\n",
    "    frames = emb_info[id].iloc[emb_clu.labels_==best_cluster_id].index.values\n",
    "    clustered_median_emb[id] = np.median(emb_info[id].loc[frames],axis=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd873bc-e70c-4c79-b492-46de02bcebb9",
   "metadata": {},
   "source": [
    "# Get potential visual matches for non overlapping IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb750c6-cd68-4303-aeb5-a8b78d99079a",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_scores = {}\n",
    "match_info = {}\n",
    "for idA in sorted(clustered_median_emb.keys()):\n",
    "    for idB in sorted(clustered_median_emb.keys()):\n",
    "        if idB in match_scores.keys():\n",
    "            continue\n",
    "        # check if idA and idB overlaps, if not, Just leave them be\n",
    "        min_idxA, max_idxA = df_id_start_stop[df_id_start_stop['id']==idA][['min_idx','max_idx']].values[0].tolist()\n",
    "        min_idxB, max_idxB = df_id_start_stop[df_id_start_stop['id']==idB][['min_idx','max_idx']].values[0].tolist()\n",
    "        if len(range(max(min_idxA,min_idxB), min(max_idxA,max_idxB))) > 0:\n",
    "            #overlapping ranges\n",
    "            continue\n",
    "        match_distance = cdist(clustered_median_emb[idA].reshape(1,-1), clustered_median_emb[idB].reshape(1,-1))[0][0]\n",
    "        if match_distance < DISTANCE_THRESHOLD:\n",
    "            if idA not in match_scores:\n",
    "                match_scores[idA] = {}\n",
    "            match_scores[idA][idB] = 1 - match_distance\n",
    "        \n",
    "df_matching_method = pd.DataFrame(match_scores)\n",
    "df_matching_method.shape    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea00bd76-1204-46cf-97f3-1a1ff5f8a88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Rectangle\n",
    "fig, axn = plt.subplots(1,1,figsize=(15,10))\n",
    "sns.heatmap(df_matching_method.round(2), annot=True, annot_kws={'fontsize':30},ax=axn,cmap='Blues', vmax=1, vmin=0, linewidths=1)\n",
    "# for gtA in map(int, gt_map):\n",
    "#     for gtB in map(int, gt_map[str(gtA)]):\n",
    "#         if (gtA>=0) and (gtB>=0):\n",
    "#             if (gtA in df_matching_methodC.columns) and (gtB in df_matching_methodC.index):\n",
    "#                 locA, locB = df_matching_methodC.columns.get_loc(gtA), df_matching_methodC.index.get_loc(gtB)\n",
    "#                 axn.add_patch(Rectangle((locA, locB), 1, 1, fill=False, edgecolor='red', lw=4))\n",
    "\n",
    "# for locA in range(df_matching_method.shape[1]):\n",
    "#     locBs = df_matching_method.iloc[:,locA].argsort()[:1]\n",
    "#     for locB in locBs:\n",
    "#         axn.add_patch(Rectangle((locA, locB), 1, 1, fill=False, edgecolor='blue', lw=1))\n",
    "\n",
    "plt.xticks(fontsize=30)\n",
    "plt.yticks(fontsize=30)\n",
    "axn.set_xlabel(f\"Student IDs\",fontsize=40)\n",
    "axn.set_ylabel(f\"Student IDs\",fontsize=40)\n",
    "cbar = axn.collections[0].colorbar\n",
    "cbar.ax.tick_params(labelsize=20)\n",
    "plt.savefig(f'case_studies/plots/self_match_{course}_{session.split(\"_\")[-1]}.png',dpi=400,bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f259d80-480f-4234-9f51-1dc361c9396c",
   "metadata": {},
   "source": [
    "#### Get Bounding Box overlap for non-overlapping ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2d38fc-56a0-4519-9536-506db52bc3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_scores = {}\n",
    "def bbox_overlap_metric(bu, bv):\n",
    "    X_TL1, Y_TL1, X_BR1, Y_BR1 = bu[:4]\n",
    "    p1, p2, p3, p4  = map(Point, [[X_TL1,Y_TL1], [X_TL1,Y_BR1], [X_BR1,Y_BR1],[X_BR1, Y_TL1]]) \n",
    "    id_polygon = Polygon(p1, p2, p3, p4)\n",
    "    X_TL2, Y_TL2, X_BR2, Y_BR2 = bv[:4]\n",
    "    p1, p2, p3, p4  = map(Point, [[X_TL2,Y_TL2], [X_TL2,Y_BR2], [X_BR2,Y_BR2],[X_BR2, Y_TL2]]) \n",
    "    matched_id_polygon = Polygon(p1, p2, p3, p4)\n",
    "    if id_polygon.encloses_point(matched_id_polygon.centroid) & matched_id_polygon.encloses_point(id_polygon.centroid):\n",
    "        X_TL_in, X_BR_in = sorted([X_TL1,X_TL2, X_BR1, X_BR2])[1:3]\n",
    "        Y_TL_in, Y_BR_in = sorted([Y_TL1,Y_TL2, Y_BR1, Y_BR2])[1:3]\n",
    "        p1, p2, p3, p4  = map(Point, [[X_TL_in,Y_TL_in], [X_TL_in,Y_BR_in], [X_BR_in,Y_BR_in],[X_BR_in, Y_TL_in]]) \n",
    "        intersection = Polygon(p1, p2, p3, p4)            \n",
    "        #find polygon overlap\n",
    "        area_intersection = np.abs(intersection.area)\n",
    "        area_union = np.abs(id_polygon.area) + np.abs(matched_id_polygon.area) - area_intersection\n",
    "        overlap_fraction  = (area_intersection/area_union).evalf()\n",
    "    else:\n",
    "        overlap_fraction=0.                \n",
    "\n",
    "    return overlap_fraction\n",
    "\n",
    "# test sample\n",
    "bbox_overlap_metric(bbox_info[0].loc[0], bbox_info[0].loc[6])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a0a5b8-5342-4cee-a0eb-0da2ed1a6275",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_overlapping_metric(bu, bv, eps_fraction=0.1):\n",
    "    X_TL1, Y_TL1, X_BR1, Y_BR1 = bu[:4]\n",
    "    X_TL2, Y_TL2, X_BR2, Y_BR2 = bv[:4]\n",
    "    eps_distance = min(X_BR1-X_TL1, X_BR2-X_TL2, Y_BR1-Y_TL1, Y_BR2-Y_TL2)*eps_fraction\n",
    "    # if rectangle has area 0, no overlap\n",
    "    if X_TL1 == X_BR1 or Y_TL1 == Y_BR1 or X_TL2 == X_BR2 or Y_TL2 == Y_BR2:\n",
    "        return False\n",
    "     \n",
    "    # If one rectangle is on left side of other\n",
    "    if X_TL1 > X_BR2-eps_distance or X_TL2 > X_BR1-eps_distance:\n",
    "        return False\n",
    " \n",
    "    # If one rectangle is above other\n",
    "    if Y_TL1 > Y_BR2 - eps_distance or Y_TL2 > Y_BR1 - eps_distance:\n",
    "        return False\n",
    " \n",
    "    return True\n",
    "\n",
    "# test sample\n",
    "is_overlapping_metric(bbox_info[0].loc[0], bbox_info[0].loc[6])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598c9126-0365-47c8-a17b-34c90cd4406b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for idA in sorted(clustered_median_emb.keys()):\n",
    "    for idB in sorted(clustered_median_emb.keys()):\n",
    "        if idB in match_scores.keys():\n",
    "            continue\n",
    "        # check if idA and idB overlaps, if not, Just leave them be\n",
    "        min_idxA, max_idxA = df_id_start_stop[df_id_start_stop['id']==idA][['min_idx','max_idx']].values[0].tolist()\n",
    "        min_idxB, max_idxB = df_id_start_stop[df_id_start_stop['id']==idB][['min_idx','max_idx']].values[0].tolist()\n",
    "        if len(range(max(min_idxA,min_idxB), min(max_idxA,max_idxB))) > 0:\n",
    "            #overlapping ranges\n",
    "            continue\n",
    "        bbox_overlap_matrix = cdist(bbox_info[idA].iloc[:1000], bbox_info[idB].iloc[:1000], metric = is_overlapping_metric)\n",
    "        bbox_overlap = np.mean(bbox_overlap_matrix.flatten())\n",
    "        sprint(idA, idB, bbox_overlap)\n",
    "        if bbox_overlap > OVERLAP_THRESHOLD:\n",
    "            if idA not in overlap_scores:\n",
    "                overlap_scores[idA] = {}\n",
    "            overlap_scores[idA][idB] = bbox_overlap\n",
    "        \n",
    "df_overlap = pd.DataFrame(overlap_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9a0aa4-6489-45a7-87ea-7404317014b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdist(bbox_info[idA].sample(500), bbox_info[idB].sample(500), metric = is_overlapping_metric).flatten().mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87af5f79-b0d7-42db-ac83-89e537480c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axn = plt.subplots(1,1,figsize=(15,10))\n",
    "sns.heatmap(df_overlap.round(2), annot=True, annot_kws={'fontsize':15},ax=axn,cmap='Reds', vmax=1, vmin=0, linewidths=1)\n",
    "axn.set_xlabel(f\"Session: {session}\",fontsize=16)\n",
    "axn.set_ylabel(f\"Session: {session}\",fontsize=16)\n",
    "plt.xticks(fontsize=30)\n",
    "plt.yticks(fontsize=30)\n",
    "axn.set_xlabel(f\"Student IDs\",fontsize=40)\n",
    "axn.set_ylabel(f\"Student IDs\",fontsize=40)\n",
    "cbar = axn.collections[0].colorbar\n",
    "cbar.ax.tick_params(labelsize=20)\n",
    "plt.savefig(f'case_studies/plots/self_overlap_{course}_{session.split(\"_\")[-1]}.png',dpi=400,bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d29f96-9bbd-4c2a-b0c7-5e38729620af",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axn = plt.subplots(1,1,figsize=(15,10))\n",
    "df_overlap_matches= deepcopy(df_matching_method)\n",
    "for col in df_overlap_matches.columns:\n",
    "    for idx in df_overlap_matches.index:\n",
    "        if (col in df_overlap.columns) and (idx in df_overlap.index):\n",
    "            df_overlap_matches.loc[idx, col] = df_overlap.loc[idx,col]\n",
    "        elif (idx in df_overlap.columns) and (col in df_overlap.index):\n",
    "            df_overlap_matches.loc[idx, col] = df_overlap.loc[col,idx]\n",
    "        else:\n",
    "            df_overlap_matches.loc[idx, col] = np.nan\n",
    "            \n",
    "sns.heatmap(df_overlap_matches.round(2), annot=True, annot_kws={'fontsize':30},ax=axn,cmap='Reds', vmax=1, vmin=0, linewidths=1)\n",
    "axn.set_xlabel(f\"Session: {session}\",fontsize=16)\n",
    "axn.set_ylabel(f\"Session: {session}\",fontsize=16)\n",
    "plt.xticks(fontsize=30)\n",
    "plt.yticks(fontsize=30)\n",
    "axn.set_xlabel(f\"Student IDs\",fontsize=40)\n",
    "axn.set_ylabel(f\"Student IDs\",fontsize=40)\n",
    "cbar = axn.collections[0].colorbar\n",
    "cbar.ax.tick_params(labelsize=20)\n",
    "plt.savefig(f'case_studies/plots/self_overlap_{course}_{session.split(\"_\")[-1]}.png',dpi=400,bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4608f036-12b4-4bbf-95dd-1460579acff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find common map between overlap and embedding matching\n",
    "df_overlap_melted = df_overlap.reset_index().melt(id_vars='index')\n",
    "df_overlap_melted = df_overlap_melted[~df_overlap_melted['value'].isnull()]\n",
    "df_overlap_melted['id_pair'] = df_overlap_melted.apply(lambda row: tuple(sorted([int(row['index']),int(row['variable'])])), axis=1)\n",
    "df_overlap_melted = df_overlap_melted[['id_pair','value']]\n",
    "df_overlap_melted\n",
    "\n",
    "df_match_melted = df_matching_method.reset_index().melt(id_vars='index')\n",
    "df_match_melted = df_match_melted[~df_match_melted['value'].isnull()]\n",
    "df_match_melted['id_pair'] = df_match_melted.apply(lambda row: tuple(sorted([int(row['index']),int(row['variable'])])), axis=1)\n",
    "df_match_melted = df_match_melted[['id_pair','value']]\n",
    "df_match_melted\n",
    "\n",
    "df_eligible_pairs = pd.merge(df_overlap_melted, df_match_melted, on='id_pair',suffixes=('_overlap','_match'))\n",
    "\n",
    "df_eligible_pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c265f50e-9b12-416b-8510-912573853c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find common map between overlap and embedding matching\n",
    "df_overlap_melted = df_overlap.reset_index().melt(id_vars='index')\n",
    "df_overlap_melted = df_overlap_melted[~df_overlap_melted['value'].isnull()]\n",
    "df_overlap_melted['id_pair'] = df_overlap_melted.apply(lambda row: tuple(sorted([int(row['index']),int(row['variable'])])), axis=1)\n",
    "df_overlap_melted = df_overlap_melted[['id_pair','value']]\n",
    "df_overlap_melted\n",
    "\n",
    "df_match_melted = df_matching_method.reset_index().melt(id_vars='index')\n",
    "df_match_melted = df_match_melted[~df_match_melted['value'].isnull()]\n",
    "df_match_melted['id_pair'] = df_match_melted.apply(lambda row: tuple(sorted([int(row['index']),int(row['variable'])])), axis=1)\n",
    "df_match_melted = df_match_melted[['id_pair','value']]\n",
    "df_match_melted\n",
    "\n",
    "df_eligible_pairs = pd.merge(df_overlap_melted, df_match_melted, on='id_pair',suffixes=('_overlap','_match'))\n",
    "\n",
    "df_eligible_pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ee08fb-3c39-4bb2-a5f2-6ca21bd07707",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_match_melted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6556666-7e6f-44d7-950f-495faea893ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_overlap_melted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048323ad-63e9-4280-a438-19d139e7e69d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5148e47-f8a0-4749-9734-3b17446e8f5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
